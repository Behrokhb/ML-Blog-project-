{
  "hash": "01bd64789f69af5f959e289bddc2681d",
  "result": {
    "markdown": "---\ntitle: \"Linear/Non-linear Regression\"\nauthor: \"Behrokh Bazmara\"\ndate: \"2023-12-01\"\ncategories: [news, code, analysis]\n---\n\n\nIn my predictive modeling approach, I employed a Random Forest model to predict the occurrence of crashes. Random Forest is an ensemble learning method that combines the predictions of multiple decision trees to enhance overall accuracy and robustness. The data set used for modeling contained a variety of relevant features such as mix types, lane counts, roadway geometry, pavement condition, and environmental characteristics, which could influence crash outcome.\n\nI began by splitting the data set into training and testing sets to evaluate the model's performance. The Random Forest algorithm was then applied to the training data, where a multitude of decision trees were constructed, each trained on a different subset of the data and considering a random subset of features for each split. This diversity and randomness helped mitigate overfitting and increased the model's generalization ability. During the prediction phase, the ensemble of trees collectively contributed to a more accurate and stable prediction of crash occurrences.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n                   # Random Forest Regression\n\n#Loading dataset\nsetwd('C:/Users/behro/OneDrive/Desktop/SS-Infrastructure/project')\n\n#Install the packages\nlibrary(MASS)\nlibrary(lme4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'lme4' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'Matrix' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(randomForest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'randomForest' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nrandomForest 4.7-1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nType rfNews() to see new features/changes/bug fixes.\n```\n:::\n\n```{.r .cell-code}\nlibrary(caTools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'caTools' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"randomForest\")\n#install.packages(\"pdp\")\n#install.packages(\"randomForestExplainer\")\n#install.packages(\"ggplot2\")\n#install.packages(\"Boruta\")\nlibrary(Boruta)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'Boruta' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(randomForest)\nlibrary(randomForestExplainer)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'randomForestExplainer' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'ggplot2'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:randomForest':\n\n    margin\n```\n:::\n\n```{.r .cell-code}\n# View the structure of the data set (Read in data)\nFitData2<-read.csv('Book3.csv') \nnames(FitData2)#looking at the data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n```\n:::\n\n```{.r .cell-code}\n#splitting data into training and testing\nsplit <- sample.split(FitData2, SplitRatio=0.7)\ntrain <- subset(FitData2, split==\"TRUE\")\ntest <- subset (FitData2, split==\"FALSE\")\n\n# Fitting the random forest model\nset.seed(100) #Setting seed\nclassRF= randomForest(x=train[-13], y=train$Crash, ntree=500)\nclassRF\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\n randomForest(x = train[-13], y = train$Crash, ntree = 500) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 6\n\n          Mean of squared residuals: 0.8465309\n                    % Var explained: 95.66\n```\n:::\n\n```{.r .cell-code}\n#Model prediction\nrf_model=predict(classRF, newdata= test[-13])\nsummary(rf_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0191  0.9753  2.0106  2.0130 38.2434 \n```\n:::\n\n```{.r .cell-code}\n# Create a scatterplot of actual vs. predicted values\nplot(classRF$predicted, train$Crash,\n     main = \"Scatterplot of Actual vs. Predicted Values\",\n     xlab = \"Actual Values\", ylab = \"Predicted Values\",\n     col = \"darkblue\", pch = 16)\n\n# Add a diagonal line for reference\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}