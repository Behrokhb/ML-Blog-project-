[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ML Project",
    "section": "",
    "text": "Clssification\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nBehrokh Bazmara\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustering\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nBehrokh Bazmara\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear/Non-linear Regression\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nBehrokh Bazmara\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutliers Detection\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nBehrokh Bazmara\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability Theory\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nBehrokh Bazmara\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/clustering/index.html",
    "href": "posts/clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "In my R code, I employed the elbow method to determine the optimal number of clusters for a clustering analysis on a crash data set.\nThe data set included crucial features such as roadway “lane_count” and “mix type”, which are essential factors in understanding the characteristics of different road segments concerning safety.\nThe first step involved selecting and possibly standardizing these features to ensure uniform contributions to the clustering process.\nSubsequently, I applied the k-means clustering algorithm across a range of cluster numbers (k) and calculated the sum of squared distances within clusters (WSS) for each configuration. The elbow method involves plotting the number of clusters against the corresponding WSS and visually or programmatically identifying the “elbow” point, which signifies the optimal k where additional clusters cease to significantly improve the clustering performance.\nThis data-driven approach allowed me to discern the natural structure within the crash data set based on lane_count and mix type, providing valuable insights into potential groupings of roadway segments with distinct safety characteristics.\n\n#Importing required libararies\n#install.packages(\"FactoMineR\")\n#install.packages(\"factoextra\")\nlibrary(cluster)\nlibrary(parameters)\n\nWarning: package 'parameters' was built under R version 4.2.3\n\n#Read in data\nFitData2<-read.csv('Book3.csv') \n\n#Scaling data\nFitData2 <- scale(FitData2)\n\n#View in data \n#head(FitData2)\n\n#Elbow Method (Number of clusters)\nk.max <- 10\nwss <- sapply(2:k.max, function(k){kmeans(FitData2,k, nstart=10)$tot.withinss})\n#print(wss)\nplot(2:k.max, wss, type=\"b\", pch=16, xlab=\"Number of Cluster K\", \nylab=\"Total within cluster sum of squares\")\n\n\n\n#Finding optimal clusters to the training\nkmeans <- kmeans(FitData2, centers=4, nstart = 10)\n\n#100*kmeans$betweenss / kmeans$totss\n\n\n# #Visualizing clusters \nclusplot(FitData2[,6:7],\n         kmeans$cluster,\n         lines = 0,\n         shade = TRUE,\n         color = TRUE,\n         labels = 2,\n         plotchar = FALSE,\n         span = TRUE,\n         main = paste(\"Cluster of data\"),\n         xlab = '',\n         ylab = '')\nlegend(\"topleft\", legend=c(\"Cluster 1\", \"Cluster 2\", \"Cluster 3\", \"Cluster 4\"), col = c(\"blue\", \"red\", \"purple\",\"green\"), lty= 1:2, cex = 0.8)"
  },
  {
    "objectID": "posts/clustering/index.html#running-code",
    "href": "posts/clustering/index.html#running-code",
    "title": "Post With Code",
    "section": "Running Code",
    "text": "Running Code\n\n#Importing required libararies\n#install.packages(\"FactoMineR\")\n#install.packages(\"factoextra\")\nlibrary(cluster)\nlibrary(parameters)\n\nWarning: package 'parameters' was built under R version 4.2.3\n\n#Read in data\nFitData2<-read.csv('Book3.csv') \n\n#Scaling data\nFitData2 <- scale(FitData2)\n\n#View in data (to show only the first 6 obs)\nhead(FitData2)\n\n          AADT  Latitude  Longitude       yn   Divided  LaneCount       DGAC\n[1,] 0.1993203 0.6942351 0.53628179 1.740905 0.5809847  0.6354780  0.9904607\n[2,] 1.4441855 0.9618887 0.07132134 1.740905 0.5809847  0.6354780  0.9904607\n[3,] 0.8513925 0.5604786 0.29580406 1.740905 0.5809847  0.6354780  0.9904607\n[4,] 0.7031943 0.5744380 0.07147596 1.740905 0.5809847 -0.7464594 -1.0095167\n[5,] 0.1993203 0.6905834 0.53277468 1.740905 0.5809847  0.6354780  0.9904607\n[6,] 0.8513925 0.5623230 0.29886758 1.740905 0.5809847  0.6354780  0.9904607\n          Latex        SMA       PCCP        Age   Friction       Macro\n[1,] -0.2957116 -0.7624168 -0.2225268  0.1257461 -1.7161182 -0.92240866\n[2,] -0.2957116 -0.7624168 -0.2225268 -0.6351171 -0.2381688 -0.06114685\n[3,] -0.2957116 -0.7624168 -0.2225268 -0.7438119 -1.2064037 -0.08906667\n[4,]  3.3812893 -0.7624168 -0.2225268 -0.4177276 -1.4979871 -0.53264054\n[5,] -0.2957116 -0.7624168 -0.2225268  0.1257461 -1.3733408  2.00818660\n[6,] -0.2957116 -0.7624168 -0.2225268 -0.2003381 -1.4267607  0.24523161\n             IRI   Gradient  Curvature LatitudeGPS LongitudeGps     Crash\n[1,]  5.43785155 -1.8306516 -0.1578357   0.6938036   0.53592716 18.793822\n[2,] -0.71783343 -0.5300452 -0.3895533   0.9621143   0.07148326 19.020246\n[3,]  0.44407303 -0.2964816  0.0851068   0.5606330   0.29573638  9.736856\n[4,]  0.02150828 -0.2579325 -0.2805097   0.5744591   0.07103375  8.604735\n[5,]  5.49958478 -0.4749798  0.3192299   0.6906183   0.53272813  9.736856\n[6,]  1.30672332  0.5578629 -0.2869237   0.5619373   0.29885927  9.510431\n        lnAADT\n[1,] 0.7212908\n[2,] 1.3049672\n[3,] 1.0823260\n[4,] 1.0143630\n[5,] 0.7212908\n[6,] 1.0823260\n\n#Elbow Method (Number of clusters)\nk.max <- 10\nwss <- sapply(2:k.max, function(k){kmeans(FitData2,k, nstart=10)$tot.withinss})\nprint(wss)\n\n[1] 144481.06 128944.26 114596.58 105740.67  99248.42  94035.94  89150.51\n[8]  85374.03  82602.41\n\nplot(2:k.max, wss, type=\"b\", pch=16, xlab=\"Number of Cluster K\", \nylab=\"Total within cluster sum of squares\")\n\n\n\n#Finding optimal clusters to the training\nkmeans <- kmeans(FitData2, centers=4, nstart = 10)\nkmeans\n\nK-means clustering with 4 clusters of sizes 3026, 2513, 416, 2861\n\nCluster means:\n        AADT   Latitude  Longitude         yn     Divided  LaneCount       DGAC\n1  0.8770739  0.5919002  0.5914139 -0.3295104  0.43948673  0.1966010 -0.8978194\n2 -0.3101564  0.6165771  0.2535115  0.6684991 -0.55398715  0.2538367  0.7723971\n3 -0.4692725  0.2381404  1.0833591 -0.1068457  0.52564807 -0.3312138 -1.0095167\n4 -0.5869924 -1.2022421 -1.0057218 -0.2231360 -0.05466156 -0.3827408  0.4179400\n        Latex        SMA       PCCP         Age   Friction       Macro\n1 -0.26897864  1.1805668 -0.2225268 -0.15256416 -0.5639657  0.23121397\n2 -0.06452732 -0.6666862 -0.2225268 -0.24047689 -0.1618609 -0.25389505\n3 -0.29571163 -0.7624168  4.4933303  2.92176167  0.1627102 -0.51405064\n4  0.38416727 -0.5522011 -0.2225268 -0.05224581  0.7150050  0.05320862\n         IRI      Gradient   Curvature LatitudeGPS LongitudeGps      Crash\n1 -0.3998239 -0.0025061557 -0.07454425   0.5918961    0.5914141  0.1893281\n2  0.4895974  0.0110941125  0.18475072   0.6165807    0.2535109  0.2438895\n3  1.0509540 -0.0431156854 -0.18605297   0.2381459    1.0833455 -0.2737052\n4 -0.1599749 -0.0008247998 -0.05638225  -1.2022417   -1.0057195 -0.3746732\n       lnAADT\n1  0.71506901\n2 -0.09193137\n3 -0.49006278\n4 -0.60430240\n\nClustering vector:\n   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2\n  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n  [75] 2 1 2 2 2 2 1 2 2 2 2 1 2 2 3 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 1\n [112] 2 2 1 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 1\n [149] 2 2 2 2 2 1 2 2 1 1 1 1 2 1 2 2 2 2 2 2 2 1 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2\n [186] 2 1 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 1 2 2 1 2 1 2 2 1 1 2 2 2 2 1 1 2\n [223] 2 1 2 2 2 2 2 2 2 2 1 1 2 2 2 1 1 2 2 1 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 1 1\n [260] 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 3 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 1 1\n [297] 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2\n [334] 2 2 2 2 1 2 2 2 2 1 1 1 2 2 2 2 1 1 2 2 2 1 2 2 1 2 2 2 2 1 2 2 2 2 2 1 2\n [371] 2 2 2 2 1 1 2 2 1 2 1 1 1 2 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 2 2 2 2 2\n [408] 2 1 1 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 1 2 2 2 2 1 1 1 2 2 1 1 2 4 2 2\n [445] 1 1 2 2 2 1 2 2 1 2 2 2 2 1 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 3 2 2 1 1 2 2 2\n [482] 2 1 1 2 2 2 2 2 1 1 1 2 2 1 2 2 1 2 2 1 1 2 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2\n [519] 2 2 2 2 2 3 2 2 1 2 1 2 2 2 2 1 2 1 1 1 2 2 1 1 1 1 1 2 2 2 1 1 1 1 2 3 1\n [556] 1 1 1 2 2 2 2 2 1 2 1 2 1 2 1 1 1 2 2 2 1 1 2 2 2 1 1 2 2 2 1 1 1 1 2 1 2\n [593] 2 1 2 2 1 2 1 1 2 2 1 2 2 2 1 2 2 2 1 1 2 1 1 2 1 1 1 2 2 1 2 2 1 1 1 1 1\n [630] 1 1 2 1 1 1 2 1 1 1 1 2 2 2 1 1 1 1 4 2 1 1 1 1 2 2 2 2 1 2 1 1 1 1 1 1 1\n [667] 1 2 3 1 1 2 1 2 2 2 2 1 3 2 2 1 2 1 2 2 2 3 1 1 2 2 3 1 1 2 2 2 2 2 2 1 2\n [704] 1 1 1 1 1 3 1 2 1 1 2 1 1 2 1 1 2 1 2 2 1 1 2 1 1 3 2 2 2 1 1 2 2 1 2 1 2\n [741] 1 2 1 1 1 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 4 1 1 2 1 1 2 1 1 1 2 1 2 1 2 2\n [778] 1 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 2 2 2 1 1 2 1 1 1 1\n [815] 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 1 2 2 2 1 2 1 1 1\n [852] 1 1 1 1 2 1 1 2 2 4 2 4 2 1 1 1 1 2 1 2 2 2 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1\n [889] 2 2 2 1 2 2 1 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 2 2 2 2 1 2 1 1 1 2 1 1 2 2 1\n [926] 1 1 2 2 2 4 1 2 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 2 1 2 1 1 1 1 4 1 4 4 2 2 2\n [963] 1 1 2 2 2 1 2 1 1 1 2 2 1 2 2 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 2 1 4 1 1 2 2\n[1000] 3 1 2 2 2 1 2 1 2 1 1 1 2 1 1 2 1 1 2 4 2 2 1 1 2 1 2 1 2 2 2 1 1 2 1 2 1\n[1037] 2 1 1 1 2 2 1 1 1 1 2 2 1 2 2 4 1 2 2 1 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 2\n[1074] 1 2 1 2 1 1 1 2 1 2 1 2 1 1 2 1 2 2 2 1 1 1 1 1 1 1 2 2 4 2 2 1 2 1 1 1 2\n[1111] 3 2 1 2 2 2 1 3 1 1 2 1 1 2 1 1 2 1 1 1 2 1 2 1 1 2 2 2 2 4 4 1 1 3 1 1 2\n[1148] 1 1 2 2 2 1 1 2 1 2 3 1 1 1 2 4 4 1 1 1 2 2 2 1 2 1 2 1 2 1 1 1 1 2 1 1 1\n[1185] 2 2 1 2 4 2 1 2 1 1 2 1 1 2 1 3 2 4 1 2 1 1 1 4 1 1 1 1 1 2 2 1 2 2 1 2 3\n[1222] 1 1 2 1 2 1 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 4 1 2 1 1 1 1 2 2 1 1 1 1\n[1259] 1 1 2 1 1 1 1 2 1 1 2 3 2 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 2 1 2 1 1\n[1296] 1 1 1 1 1 2 2 1 1 1 1 4 1 2 2 4 2 1 2 2 2 2 2 3 1 1 1 2 2 2 1 2 1 2 1 1 2\n[1333] 1 1 2 2 2 2 2 1 1 1 2 2 1 2 1 1 1 1 2 1 2 2 2 1 1 1 4 1 2 1 1 4 4 1 1 1 1\n[1370] 2 1 2 1 1 1 1 2 1 1 1 2 1 2 2 1 1 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 1 1 1 1 1\n[1407] 2 1 1 2 2 1 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1\n[1444] 1 1 2 1 2 1 1 2 2 1 1 1 1 4 1 2 2 1 1 1 1 2 1 1 2 2 2 1 1 1 1 1 1 1 2 2 4\n[1481] 2 1 1 1 2 2 2 1 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 2 4 2 2 1 1 2 2 1 1 4 1 4\n[1518] 2 1 4 1 1 2 1 2 1 1 2 1 2 1 4 2 1 2 1 2 1 4 1 1 2 1 2 1 1 1 1 2 1 2 3 1 1\n[1555] 1 1 2 1 2 4 1 2 1 2 2 1 1 1 1 2 1 1 1 2 1 1 2 2 2 2 1 3 2 2 1 1 1 2 2 3 1\n[1592] 2 1 1 1 1 1 1 2 1 1 1 2 1 4 2 2 2 2 1 2 2 2 2 2 1 1 1 1 2 1 2 1 1 2 2 2 2\n[1629] 1 1 2 1 2 3 1 1 4 1 1 1 2 1 2 1 2 2 1 4 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1\n[1666] 1 3 1 1 2 1 1 2 1 1 1 2 1 4 1 2 4 1 2 2 2 1 1 2 4 1 1 1 2 4 1 1 1 1 1 1 1\n[1703] 1 1 2 1 2 1 1 1 2 4 2 1 2 3 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 4 1 4 1 1 2 2\n[1740] 1 4 1 1 1 2 2 2 1 1 4 1 1 1 4 4 2 1 2 1 2 1 1 1 2 1 1 1 1 2 2 2 4 1 1 1 1\n[1777] 1 1 1 1 2 1 1 2 4 1 2 1 2 1 1 2 1 1 2 2 1 2 2 1 1 1 1 3 1 1 1 2 2 2 2 1 2\n[1814] 1 3 1 1 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 4 2 1 1 2 1 4 1 1 2 2 2 2\n[1851] 1 2 1 1 4 2 1 2 2 2 4 1 4 4 1 2 2 2 1 1 2 1 1 1 2 2 2 1 2 4 1 1 1 2 1 2 1\n[1888] 4 1 1 1 1 2 1 2 4 1 1 1 2 1 4 2 1 1 1 1 1 1 1 1 4 2 1 2 2 2 1 4 2 1 4 1 1\n[1925] 2 2 2 1 2 1 1 1 2 1 1 1 1 2 1 1 1 3 1 2 2 1 1 2 2 4 1 1 4 2 2 1 1 1 2 1 1\n[1962] 2 1 2 2 4 2 2 2 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 1 1 1 1 2 1 1 4\n[1999] 1 1 2 1 1 1 2 1 1 1 1 4 1 3 1 2 1 1 2 2 1 2 2 4 1 1 2 1 2 2 1 1 1 1 1 3 1\n[2036] 1 1 1 1 1 2 1 2 4 1 4 2 4 1 1 2 1 4 2 1 2 2 2 4 2 1 2 4 1 1 1 1 1 1 1 1 2\n[2073] 1 2 1 1 1 4 4 1 2 1 1 4 2 2 1 1 1 1 4 2 1 2 1 2 1 2 1 2 2 1 1 1 4 4 1 2 2\n[2110] 1 1 1 4 2 1 1 2 2 1 2 4 1 1 1 1 1 1 1 1 2 1 1 2 2 1 4 2 4 1 4 4 1 1 2 1 1\n[2147] 1 2 1 1 2 1 1 1 4 1 1 1 2 4 1 1 4 4 1 4 1 1 1 1 1 2 1 4 2 1 1 1 2 1 1 1 1\n[2184] 1 2 1 4 4 1 2 1 2 1 4 1 1 4 1 1 1 4 1 2 1 1 4 1 2 1 2 1 1 1 2 1 4 2 2 2 1\n[2221] 2 2 2 2 2 1 1 1 4 1 2 4 1 1 1 2 1 4 1 4 1 2 2 4 1 4 1 4 4 1 1 2 1 1 2 1 1\n[2258] 2 4 1 1 2 1 1 1 4 2 1 4 1 1 4 1 1 1 2 2 2 1 1 1 1 3 1 1 1 1 1 1 1 2 1 1 1\n[2295] 1 2 4 1 4 1 4 2 4 4 2 1 1 1 4 2 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 4 1 1 1 1\n[2332] 1 2 1 2 1 2 2 1 1 1 1 3 1 1 1 1 1 2 2 1 2 1 4 1 2 2 1 2 2 2 4 1 2 1 1 2 1\n[2369] 2 1 1 1 1 3 1 4 4 1 1 1 2 1 1 2 2 4 2 1 1 1 4 1 2 4 1 1 3 2 2 1 4 4 4 1 1\n[2406] 1 2 4 2 2 4 1 1 2 2 3 2 1 1 2 4 1 1 2 1 1 4 1 2 4 1 4 1 1 2 1 1 4 2 1 1 2\n[2443] 1 2 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 4 4 1 1 2 2 2 1 1 1 1 1 1 2 2 2 4\n[2480] 4 1 2 1 1 1 4 4 2 1 4 4 2 1 2 1 4 1 2 1 1 1 2 1 1 3 3 4 1 2 1 1 4 1 1 1 1\n[2517] 2 2 3 4 1 1 2 1 1 1 2 2 1 2 4 1 4 2 4 1 1 1 2 1 4 1 2 1 4 1 1 1 1 1 2 1 2\n[2554] 1 1 1 4 1 1 4 1 1 1 1 4 1 1 1 1 2 2 1 2 1 1 4 1 1 1 3 3 1 1 4 2 4 4 2 1 1\n[2591] 2 1 4 1 1 4 1 2 1 2 2 2 1 4 2 2 2 1 2 4 4 1 4 1 2 1 4 4 1 4 3 2 1 2 1 2 1\n[2628] 1 1 4 1 2 1 1 1 2 1 1 4 4 1 4 1 4 1 2 2 1 1 1 1 1 1 1 1 4 1 1 4 2 4 2 1 1\n[2665] 1 2 1 4 4 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 4 2 2 2 1 1 1 1 1 2 1\n[2702] 2 4 2 2 1 4 1 2 1 1 2 4 1 1 2 4 1 4 1 1 1 2 2 1 1 2 4 2 1 1 1 1 1 1 1 1 4\n[2739] 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 4 1 4 4 4 4\n[2776] 2 1 1 1 1 1 1 1 1 1 4 1 2 1 2 4 1 4 1 2 1 1 4 1 1 4 1 1 1 1 2 2 2 1 1 4 1\n[2813] 4 4 1 2 1 1 2 2 4 1 4 1 2 2 4 2 2 4 2 1 4 1 1 1 1 2 4 1 1 2 1 1 2 2 4 1 4\n[2850] 4 2 4 2 1 2 1 1 1 1 1 1 2 2 4 1 1 1 2 1 4 4 1 4 1 1 2 1 1 1 4 3 2 1 1 4 2\n[2887] 1 1 2 1 1 2 1 4 1 1 1 4 1 1 2 2 1 1 1 2 1 1 2 2 4 1 1 4 1 1 4 1 1 4 1 2 1\n[2924] 3 1 4 2 3 1 1 2 1 1 1 4 1 1 1 2 2 2 4 2 2 1 3 1 1 2 2 1 2 1 1 1 4 1 2 1 1\n[2961] 2 1 4 1 4 1 1 1 2 2 1 2 2 1 1 2 1 1 2 1 1 4 4 1 4 1 1 1 1 1 1 2 2 4 1 1 1\n[2998] 2 1 1 4 2 2 1 4 2 2 1 4 2 4 2 2 1 2 1 1 4 2 1 2 2 1 1 2 2 4 1 1 2 1 1 1 1\n[3035] 2 4 1 1 2 2 1 1 3 1 1 1 4 4 1 1 2 2 2 1 4 2 2 1 1 2 1 4 1 1 1 1 2 1 2 1 2\n[3072] 3 1 1 1 1 1 4 1 1 2 2 2 1 1 1 2 1 2 2 1 2 1 2 1 1 2 1 4 1 1 4 4 1 2 1 4 1\n[3109] 4 4 2 2 4 1 1 1 4 4 2 2 1 2 4 1 2 1 1 2 1 1 2 2 2 2 3 4 1 1 1 1 1 4 4 1 1\n[3146] 1 1 1 1 1 2 2 2 1 1 2 2 1 1 1 1 1 1 2 1 1 2 4 2 2 4 4 1 2 2 1 4 4 1 2 1 1\n[3183] 4 2 1 4 1 1 1 2 1 1 4 1 1 4 4 1 4 1 2 1 1 1 2 2 1 2 2 1 2 1 1 1 4 4 2 2 1\n[3220] 4 4 1 1 1 1 2 2 1 3 4 1 1 1 1 2 1 1 2 2 2 2 1 1 1 1 2 2 1 4 2 1 2 4 2 1 1\n[3257] 1 1 4 4 2 4 1 1 1 1 1 4 2 1 1 4 4 1 2 2 4 2 2 1 1 1 1 4 2 3 4 1 1 2 2 1 1\n[3294] 2 2 1 2 1 2 1 4 1 4 4 1 2 2 2 2 2 4 1 4 1 2 2 1 2 1 1 4 1 2 2 1 1 1 4 2 1\n[3331] 1 1 1 4 1 2 2 2 4 1 1 2 1 2 1 1 2 1 2 4 4 2 1 2 2 1 2 2 2 4 1 4 1 1 4 1 2\n[3368] 4 1 1 2 1 4 2 1 1 3 2 1 1 1 4 4 1 1 2 4 4 2 4 2 2 4 1 4 2 1 4 2 1 2 1 4 1\n[3405] 2 4 1 1 1 1 4 2 2 1 2 1 4 1 1 2 1 4 1 2 1 1 4 4 4 4 1 1 4 1 2 1 2 1 2 1 4\n[3442] 2 1 2 1 1 1 3 1 2 1 1 3 4 2 4 4 1 3 2 4 2 3 1 3 2 2 1 4 4 1 1 4 2 3 4 2 1\n[3479] 2 1 1 2 2 4 2 4 1 1 1 2 1 1 4 2 1 4 1 1 1 4 4 4 1 2 1 1 2 3 2 1 2 4 2 1 4\n[3516] 4 1 4 1 2 1 1 4 1 1 1 2 4 1 2 4 4 2 2 1 2 1 1 2 1 2 2 1 4 4 2 1 1 4 4 1 2\n[3553] 1 2 1 2 2 2 1 2 3 4 1 2 1 2 1 2 2 4 1 1 1 1 2 1 2 4 4 2 4 1 2 1 1 1 2 1 2\n[3590] 1 2 1 4 1 2 2 2 2 1 1 2 1 1 4 1 2 2 2 1 2 4 2 4 1 4 1 1 1 1 1 2 3 1 4 1 1\n[3627] 4 1 1 1 4 2 4 4 4 1 2 4 4 4 4 4 4 1 2 4 1 4 1 1 3 3 2 1 3 2 1 2 1 1 4 1 4\n[3664] 4 2 4 4 3 2 1 2 2 1 4 1 2 4 1 1 1 1 4 4 4 1 4 1 1 4 1 4 4 4 1 4 1 4 2 2 3\n[3701] 3 3 1 4 2 1 1 1 2 2 2 4 2 4 4 1 4 1 4 1 1 4 4 2 1 1 1 4 4 1 4 4 2 4 4 1 2\n[3738] 2 1 4 2 1 2 2 4 4 2 1 2 2 1 2 4 2 1 4 4 2 4 2 2 1 4 2 1 2 2 2 1 2 1 1 1 1\n[3775] 1 4 1 1 4 2 1 1 2 4 2 1 2 1 1 1 4 2 2 1 4 1 2 4 1 4 4 2 2 1 1 1 4 4 2 1 2\n[3812] 1 2 1 4 2 2 2 2 4 4 4 2 2 1 2 1 4 1 2 1 4 4 4 1 4 4 4 2 2 2 1 1 1 4 4 2 4\n[3849] 2 1 2 4 4 4 2 3 1 1 2 2 1 4 2 4 2 1 1 3 3 4 4 2 3 4 3 4 3 2 1 4 1 4 2 1 2\n[3886] 1 1 1 4 2 4 2 3 2 2 1 1 1 2 4 4 4 4 2 2 4 1 1 1 2 4 4 1 2 1 4 1 4 2 4 2 4\n[3923] 2 2 2 2 1 2 1 2 4 2 1 2 2 1 1 1 4 1 1 2 4 1 4 2 2 1 1 1 2 4 4 1 1 4 4 4 2\n[3960] 1 4 2 3 2 4 1 2 2 1 1 3 4 1 3 4 2 1 4 2 4 2 4 4 4 4 4 4 4 4 1 2 2 1 2 2 2\n[3997] 1 2 4 2 2 4 2 2 1 1 2 1 2 3 2 1 4 4 4 2 2 2 1 1 1 3 4 1 2 4 4 4 1 1 2 4 4\n[4034] 2 1 4 2 2 3 1 2 2 2 4 2 2 1 2 4 2 4 4 1 2 2 1 4 1 1 1 2 2 2 4 2 2 1 1 2 4\n[4071] 2 4 2 4 2 4 2 4 4 2 2 2 1 2 1 2 2 4 4 2 1 1 1 1 2 4 2 4 2 1 2 4 4 2 2 4 2\n[4108] 2 4 4 2 4 4 2 4 3 2 1 2 2 2 2 2 4 2 3 4 4 2 4 2 4 4 2 4 1 2 4 4 2 2 1 4 4\n[4145] 1 2 1 2 1 2 2 2 2 2 4 2 4 2 2 4 1 2 2 1 3 3 1 1 2 2 2 1 2 1 2 2 4 4 4 3 1\n[4182] 2 4 4 4 4 1 4 4 2 4 4 2 1 2 2 2 3 2 3 3 2 4 4 3 1 1 2 1 2 2 2 4 3 1 2 1 2\n[4219] 2 4 2 4 4 4 4 1 4 4 3 4 4 4 1 2 1 3 4 4 3 2 4 4 2 4 3 2 2 1 2 2 4 4 2 3 2\n[4256] 2 2 4 2 2 4 2 4 2 2 2 1 3 2 4 1 3 4 4 4 2 1 2 2 4 1 2 4 1 1 4 1 4 2 4 3 3\n[4293] 2 4 2 4 2 2 1 1 4 1 1 2 4 4 1 1 4 2 2 1 1 2 1 1 4 2 2 2 1 2 4 3 3 2 2 2 1\n[4330] 1 1 1 1 2 1 2 4 2 1 1 2 2 1 4 2 4 4 2 1 1 1 2 4 2 2 1 2 2 4 2 4 1 4 4 2 4\n[4367] 2 2 4 2 3 1 1 2 1 4 2 4 2 2 2 4 2 2 3 4 4 1 1 4 4 2 4 4 3 1 4 4 2 4 4 2 1\n[4404] 4 2 1 1 2 4 1 4 2 1 2 2 4 4 2 3 4 4 4 2 2 2 2 3 1 2 4 2 4 2 2 1 4 2 4 2 4\n[4441] 4 2 2 2 4 4 2 4 4 4 2 4 1 2 4 3 4 2 1 4 1 2 2 1 1 2 1 1 1 2 2 1 4 4 4 4 2\n[4478] 4 4 1 2 4 4 1 1 2 2 4 2 2 1 2 2 2 2 4 4 1 4 1 2 4 2 1 2 4 2 2 1 2 2 1 1 1\n[4515] 2 1 2 2 4 4 4 2 4 4 2 4 4 2 1 1 4 1 4 4 2 2 2 1 2 1 2 4 1 4 4 4 1 1 2 2 1\n[4552] 2 1 4 4 1 1 1 4 1 4 2 4 3 2 2 4 4 4 2 4 4 1 2 1 2 4 1 1 1 4 4 4 2 2 1 1 4\n[4589] 2 2 4 2 2 1 2 4 1 4 1 2 3 2 2 4 1 4 2 4 4 4 1 4 4 4 2 2 3 4 1 2 4 2 1 2 4\n[4626] 3 1 1 2 4 2 4 4 4 2 2 2 4 1 1 4 4 1 1 4 2 3 2 2 1 1 2 2 2 2 1 2 4 1 3 2 2\n[4663] 1 2 3 2 4 1 1 1 1 4 1 4 4 2 2 4 1 1 2 1 1 1 4 4 4 4 4 4 4 3 4 4 1 1 4 1 4\n[4700] 4 1 1 2 1 2 4 1 2 4 2 4 4 1 4 2 1 2 1 2 4 2 4 2 1 4 1 2 3 1 2 4 2 1 1 1 4\n[4737] 4 1 2 4 3 4 1 1 2 2 4 2 2 2 4 4 1 1 1 4 1 2 4 1 3 1 4 1 4 1 4 1 2 2 2 4 2\n[4774] 4 1 1 3 4 2 1 1 4 4 4 2 2 4 1 3 4 2 4 4 4 4 4 2 2 4 1 1 3 4 1 2 1 1 4 4 2\n[4811] 4 4 4 4 2 2 4 4 2 1 1 1 1 1 2 4 1 4 1 1 1 1 2 2 2 4 4 1 4 3 4 1 4 4 2 2 1\n[4848] 1 2 4 1 1 4 1 2 1 4 1 2 4 1 1 1 3 1 3 4 4 1 2 4 3 2 1 2 2 1 1 4 1 1 2 4 2\n[4885] 2 1 2 4 1 2 2 4 4 3 1 1 1 1 4 4 4 1 1 2 2 4 1 1 1 1 1 1 1 4 1 1 4 4 4 2 1\n[4922] 3 1 1 1 1 4 4 2 1 4 1 1 4 4 1 1 2 1 1 1 3 4 3 2 1 2 4 4 4 1 1 1 3 1 2 4 1\n[4959] 4 1 2 1 1 2 1 4 2 2 1 2 2 1 1 4 4 2 1 4 4 1 4 1 1 4 1 1 4 2 1 4 1 4 4 2 4\n[4996] 4 2 4 4 2 1 1 4 4 1 4 2 1 1 2 1 4 4 3 4 1 1 1 2 1 2 4 1 4 1 1 1 1 3 4 4 2\n[5033] 1 2 2 1 1 4 4 1 1 4 2 2 2 1 3 1 2 4 4 4 1 1 4 4 4 2 1 2 2 1 4 2 1 1 1 1 1\n[5070] 2 1 4 3 4 2 2 4 2 1 4 4 1 2 4 4 2 4 2 4 4 2 1 3 2 1 4 4 4 2 1 3 4 1 3 1 1\n[5107] 4 4 1 1 1 4 4 1 2 2 3 2 4 1 1 2 4 1 1 2 4 4 2 2 2 4 2 4 1 1 1 2 1 1 4 4 1\n[5144] 4 1 4 4 4 3 2 1 4 1 4 2 1 4 2 2 1 2 4 4 2 1 2 2 2 2 1 2 1 2 4 4 1 4 1 1 4\n[5181] 2 1 1 2 1 1 1 4 3 4 3 1 2 1 1 4 2 2 4 3 4 1 4 4 1 4 1 1 4 1 1 1 2 2 4 2 2\n[5218] 1 4 1 4 4 1 1 4 3 1 4 1 1 1 4 4 1 2 4 1 4 2 2 4 1 4 1 4 4 1 2 4 1 4 3 3 1\n[5255] 1 4 1 1 2 4 1 4 1 1 1 4 4 1 1 2 4 3 1 4 2 1 2 4 4 1 1 3 2 4 1 4 4 1 2 2 4\n[5292] 1 4 4 4 4 2 2 4 1 1 2 1 1 4 1 2 1 2 4 4 1 4 2 4 4 4 4 3 1 4 4 2 2 4 4 4 2\n[5329] 1 3 1 1 4 1 2 1 4 2 4 2 1 4 1 2 2 1 4 4 4 2 1 1 4 2 4 1 4 1 4 1 4 4 4 1 1\n[5366] 2 2 4 4 1 1 1 1 4 1 4 4 2 2 2 1 2 4 2 1 3 1 4 4 4 2 4 2 3 4 4 4 2 2 2 1 1\n[5403] 1 1 2 1 2 1 4 4 1 1 2 4 4 1 2 2 1 4 2 2 1 4 1 2 1 2 1 4 4 2 2 4 2 2 1 4 1\n[5440] 4 1 1 4 4 1 1 2 1 1 1 1 4 4 1 1 4 1 4 4 4 1 1 1 4 4 4 1 2 2 2 2 4 4 2 2 2\n[5477] 4 4 1 1 2 2 2 1 2 1 1 2 4 4 4 1 4 1 2 1 2 1 4 1 2 4 4 4 2 4 2 2 1 2 2 4 4\n[5514] 4 4 4 2 4 1 4 1 4 4 2 2 1 3 4 4 1 1 1 4 4 4 4 2 4 2 4 4 4 4 4 1 4 3 4 3 4\n[5551] 4 2 1 1 1 1 4 2 1 1 4 4 1 2 2 4 1 4 4 1 1 4 4 4 4 2 4 1 4 2 4 4 1 1 4 3 3\n[5588] 4 4 4 4 1 4 3 1 4 2 2 2 1 4 1 2 2 4 2 4 2 4 3 4 1 4 4 1 4 1 1 4 4 4 4 3 4\n[5625] 1 2 4 4 4 2 4 4 4 2 4 1 4 1 2 4 4 4 2 3 4 1 4 4 1 1 1 1 4 1 4 2 4 2 1 1 4\n[5662] 4 1 1 4 1 4 1 4 1 4 2 4 1 4 1 2 4 4 2 4 4 4 4 3 4 4 4 2 1 3 4 4 1 2 2 1 4\n[5699] 4 4 2 4 4 4 4 4 4 4 1 4 2 1 1 4 4 1 4 4 1 4 3 2 1 4 2 3 1 2 4 1 4 1 1 4 4\n[5736] 4 4 4 4 4 4 1 4 4 1 1 4 2 2 4 1 4 4 4 4 1 4 4 1 4 4 4 4 4 2 1 4 1 4 1 4 4\n[5773] 3 1 4 4 4 1 1 2 2 3 4 4 4 4 4 4 4 3 4 4 2 3 3 3 4 4 1 1 2 4 2 2 4 4 3 4 1\n[5810] 1 2 4 2 1 1 4 4 4 4 1 3 4 4 4 1 4 1 4 3 1 3 4 1 2 1 4 4 4 2 4 4 4 4 4 1 1\n[5847] 4 1 4 3 2 4 4 4 4 2 4 2 2 1 4 4 4 4 1 2 4 4 4 2 1 4 4 1 2 1 4 4 3 2 1 3 2\n[5884] 1 4 3 4 1 2 4 2 1 4 1 1 4 2 3 4 1 1 4 4 4 1 2 2 4 1 4 3 1 4 1 4 4 4 4 4 4\n[5921] 4 1 3 3 1 1 4 1 4 4 2 1 4 4 1 3 3 1 4 4 1 4 1 2 4 4 2 1 3 4 4 4 1 1 4 4 2\n[5958] 3 1 1 4 4 3 4 1 4 1 4 2 4 4 4 1 4 2 3 4 1 2 4 1 4 3 1 1 4 3 1 3 2 4 2 4 4\n[5995] 4 4 4 1 4 2 2 1 4 2 4 4 4 4 4 1 1 1 4 2 4 3 2 4 4 4 1 4 4 2 4 2 3 2 1 3 3\n[6032] 4 1 1 1 3 4 4 1 1 1 4 4 1 4 4 4 4 4 1 4 4 4 4 2 4 1 4 3 2 3 4 4 4 4 4 4 2\n[6069] 4 4 1 1 4 4 1 1 4 4 4 4 4 1 3 4 4 4 4 1 2 4 4 4 4 4 4 4 4 1 4 4 4 2 1 4 3\n[6106] 4 2 4 4 4 2 4 4 4 3 2 4 4 4 4 4 1 4 4 4 3 1 4 2 4 4 2 4 4 1 4 2 4 4 2 4 4\n[6143] 4 3 4 1 1 4 4 1 4 4 1 4 4 4 1 2 4 4 2 1 3 4 4 4 2 2 4 1 4 1 4 4 4 3 3 3 1\n[6180] 1 4 4 2 1 4 4 4 3 1 1 3 3 4 2 4 4 4 1 2 4 4 4 1 1 2 2 4 2 2 2 4 1 3 4 4 4\n[6217] 4 1 2 1 1 1 1 1 3 4 1 3 4 4 4 3 2 4 4 2 3 4 2 1 1 3 2 4 4 4 4 2 4 3 4 2 4\n[6254] 3 2 2 4 4 1 2 4 4 4 4 4 4 3 4 4 4 3 2 4 2 1 4 4 4 4 4 4 2 4 2 2 4 4 2 4 4\n[6291] 4 2 4 1 3 4 4 1 2 4 2 2 2 4 2 4 4 4 4 4 4 4 4 4 3 4 4 4 2 1 2 1 2 3 3 4 4\n[6328] 4 1 1 4 4 4 4 4 4 1 4 1 4 4 1 1 4 2 4 2 1 2 4 4 3 1 4 4 4 4 2 2 4 1 2 1 2\n[6365] 4 4 4 4 4 2 1 4 4 1 4 4 4 4 2 1 4 4 2 4 1 2 4 4 4 4 4 4 4 2 4 4 1 3 2 2 4\n[6402] 4 4 3 1 3 4 2 1 4 2 4 4 1 3 2 4 4 2 4 4 2 2 4 4 4 2 1 4 2 1 1 4 1 3 2 2 1\n[6439] 3 4 3 4 2 1 1 4 2 4 4 4 2 4 4 3 4 4 2 2 3 1 4 2 4 2 2 4 4 2 1 1 3 4 4 4 1\n[6476] 2 3 4 1 3 4 4 1 3 4 1 2 2 1 2 4 2 4 4 2 4 2 2 3 2 4 4 2 4 2 4 2 2 2 4 3 2\n[6513] 1 2 4 4 2 2 4 4 4 2 4 1 4 2 2 4 4 2 3 4 2 2 2 4 1 4 4 4 2 2 1 1 2 4 4 2 4\n[6550] 4 2 1 3 3 2 2 4 2 1 1 1 4 2 4 4 1 3 4 4 4 4 1 4 1 2 1 4 4 4 4 1 2 4 4 1 4\n[6587] 4 4 4 4 4 2 2 2 3 4 3 2 4 4 1 4 4 4 4 4 4 2 2 3 4 2 1 2 4 4 2 2 3 4 1 2 2\n[6624] 4 2 2 4 4 4 2 2 2 4 4 2 4 3 2 2 4 4 2 4 3 3 3 4 4 1 4 4 2 2 1 2 3 2 2 2 4\n[6661] 4 2 4 1 4 1 4 2 4 2 1 4 4 4 4 4 2 2 4 3 4 2 2 4 2 2 2 4 4 2 4 4 2 2 1 4 3\n[6698] 1 4 4 4 1 4 4 4 2 3 4 4 4 4 1 4 2 4 2 1 4 4 4 3 4 4 4 3 4 4 4 1 4 4 1 4 1\n[6735] 1 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[6772] 3 3 3 3 3 3 3 3 3 3 3 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6809] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6846] 1 2 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6883] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6920] 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6957] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4\n[6994] 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7031] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 2 4\n[7068] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[7105] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4\n[7142] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7179] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7216] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7253] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7290] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4\n[7327] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7364] 2 4 4 4 2 4 4 4 4 4 4 4 4 2 2 4 4 4 4 4 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7401] 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7438] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7475] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7512] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7549] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7586] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7623] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7660] 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 2\n[7697] 2 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 2\n[7734] 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7771] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7808] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7845] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7882] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7919] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7956] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7993] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8030] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[8067] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8104] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8141] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1\n[8178] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8215] 4 4 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[8252] 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8289] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8326] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8363] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8400] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8437] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8474] 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8511] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8548] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8585] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8622] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8659] 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[8696] 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n[8733] 3 3 3 3 3 3 3 3 4 2 2 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2\n[8770] 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[8807] 3 3 3 3 3 3 3 3 3 3\n\nWithin cluster sum of squares by cluster:\n[1] 31196.741 41463.815  5304.779 36631.242\n (between_SS / total_SS =  35.0 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n100*kmeans$betweenss / kmeans$totss\n\n[1] 34.99911\n\n#cluster identification\nkmeans$cluster\n\n   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2\n  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n  [75] 2 1 2 2 2 2 1 2 2 2 2 1 2 2 3 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 1\n [112] 2 2 1 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 1\n [149] 2 2 2 2 2 1 2 2 1 1 1 1 2 1 2 2 2 2 2 2 2 1 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2\n [186] 2 1 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 1 2 2 1 2 1 2 2 1 1 2 2 2 2 1 1 2\n [223] 2 1 2 2 2 2 2 2 2 2 1 1 2 2 2 1 1 2 2 1 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 1 1\n [260] 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 3 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 1 1\n [297] 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2\n [334] 2 2 2 2 1 2 2 2 2 1 1 1 2 2 2 2 1 1 2 2 2 1 2 2 1 2 2 2 2 1 2 2 2 2 2 1 2\n [371] 2 2 2 2 1 1 2 2 1 2 1 1 1 2 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 2 2 2 2 2\n [408] 2 1 1 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 1 2 2 2 2 1 1 1 2 2 1 1 2 4 2 2\n [445] 1 1 2 2 2 1 2 2 1 2 2 2 2 1 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 3 2 2 1 1 2 2 2\n [482] 2 1 1 2 2 2 2 2 1 1 1 2 2 1 2 2 1 2 2 1 1 2 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2\n [519] 2 2 2 2 2 3 2 2 1 2 1 2 2 2 2 1 2 1 1 1 2 2 1 1 1 1 1 2 2 2 1 1 1 1 2 3 1\n [556] 1 1 1 2 2 2 2 2 1 2 1 2 1 2 1 1 1 2 2 2 1 1 2 2 2 1 1 2 2 2 1 1 1 1 2 1 2\n [593] 2 1 2 2 1 2 1 1 2 2 1 2 2 2 1 2 2 2 1 1 2 1 1 2 1 1 1 2 2 1 2 2 1 1 1 1 1\n [630] 1 1 2 1 1 1 2 1 1 1 1 2 2 2 1 1 1 1 4 2 1 1 1 1 2 2 2 2 1 2 1 1 1 1 1 1 1\n [667] 1 2 3 1 1 2 1 2 2 2 2 1 3 2 2 1 2 1 2 2 2 3 1 1 2 2 3 1 1 2 2 2 2 2 2 1 2\n [704] 1 1 1 1 1 3 1 2 1 1 2 1 1 2 1 1 2 1 2 2 1 1 2 1 1 3 2 2 2 1 1 2 2 1 2 1 2\n [741] 1 2 1 1 1 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 4 1 1 2 1 1 2 1 1 1 2 1 2 1 2 2\n [778] 1 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 2 2 2 1 1 2 1 1 1 1\n [815] 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 1 2 2 2 1 2 1 1 1\n [852] 1 1 1 1 2 1 1 2 2 4 2 4 2 1 1 1 1 2 1 2 2 2 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1\n [889] 2 2 2 1 2 2 1 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 2 2 2 2 1 2 1 1 1 2 1 1 2 2 1\n [926] 1 1 2 2 2 4 1 2 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 2 1 2 1 1 1 1 4 1 4 4 2 2 2\n [963] 1 1 2 2 2 1 2 1 1 1 2 2 1 2 2 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 2 1 4 1 1 2 2\n[1000] 3 1 2 2 2 1 2 1 2 1 1 1 2 1 1 2 1 1 2 4 2 2 1 1 2 1 2 1 2 2 2 1 1 2 1 2 1\n[1037] 2 1 1 1 2 2 1 1 1 1 2 2 1 2 2 4 1 2 2 1 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 2\n[1074] 1 2 1 2 1 1 1 2 1 2 1 2 1 1 2 1 2 2 2 1 1 1 1 1 1 1 2 2 4 2 2 1 2 1 1 1 2\n[1111] 3 2 1 2 2 2 1 3 1 1 2 1 1 2 1 1 2 1 1 1 2 1 2 1 1 2 2 2 2 4 4 1 1 3 1 1 2\n[1148] 1 1 2 2 2 1 1 2 1 2 3 1 1 1 2 4 4 1 1 1 2 2 2 1 2 1 2 1 2 1 1 1 1 2 1 1 1\n[1185] 2 2 1 2 4 2 1 2 1 1 2 1 1 2 1 3 2 4 1 2 1 1 1 4 1 1 1 1 1 2 2 1 2 2 1 2 3\n[1222] 1 1 2 1 2 1 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 4 1 2 1 1 1 1 2 2 1 1 1 1\n[1259] 1 1 2 1 1 1 1 2 1 1 2 3 2 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 2 1 2 1 1\n[1296] 1 1 1 1 1 2 2 1 1 1 1 4 1 2 2 4 2 1 2 2 2 2 2 3 1 1 1 2 2 2 1 2 1 2 1 1 2\n[1333] 1 1 2 2 2 2 2 1 1 1 2 2 1 2 1 1 1 1 2 1 2 2 2 1 1 1 4 1 2 1 1 4 4 1 1 1 1\n[1370] 2 1 2 1 1 1 1 2 1 1 1 2 1 2 2 1 1 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 1 1 1 1 1\n[1407] 2 1 1 2 2 1 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1\n[1444] 1 1 2 1 2 1 1 2 2 1 1 1 1 4 1 2 2 1 1 1 1 2 1 1 2 2 2 1 1 1 1 1 1 1 2 2 4\n[1481] 2 1 1 1 2 2 2 1 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 2 4 2 2 1 1 2 2 1 1 4 1 4\n[1518] 2 1 4 1 1 2 1 2 1 1 2 1 2 1 4 2 1 2 1 2 1 4 1 1 2 1 2 1 1 1 1 2 1 2 3 1 1\n[1555] 1 1 2 1 2 4 1 2 1 2 2 1 1 1 1 2 1 1 1 2 1 1 2 2 2 2 1 3 2 2 1 1 1 2 2 3 1\n[1592] 2 1 1 1 1 1 1 2 1 1 1 2 1 4 2 2 2 2 1 2 2 2 2 2 1 1 1 1 2 1 2 1 1 2 2 2 2\n[1629] 1 1 2 1 2 3 1 1 4 1 1 1 2 1 2 1 2 2 1 4 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1\n[1666] 1 3 1 1 2 1 1 2 1 1 1 2 1 4 1 2 4 1 2 2 2 1 1 2 4 1 1 1 2 4 1 1 1 1 1 1 1\n[1703] 1 1 2 1 2 1 1 1 2 4 2 1 2 3 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 4 1 4 1 1 2 2\n[1740] 1 4 1 1 1 2 2 2 1 1 4 1 1 1 4 4 2 1 2 1 2 1 1 1 2 1 1 1 1 2 2 2 4 1 1 1 1\n[1777] 1 1 1 1 2 1 1 2 4 1 2 1 2 1 1 2 1 1 2 2 1 2 2 1 1 1 1 3 1 1 1 2 2 2 2 1 2\n[1814] 1 3 1 1 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 4 2 1 1 2 1 4 1 1 2 2 2 2\n[1851] 1 2 1 1 4 2 1 2 2 2 4 1 4 4 1 2 2 2 1 1 2 1 1 1 2 2 2 1 2 4 1 1 1 2 1 2 1\n[1888] 4 1 1 1 1 2 1 2 4 1 1 1 2 1 4 2 1 1 1 1 1 1 1 1 4 2 1 2 2 2 1 4 2 1 4 1 1\n[1925] 2 2 2 1 2 1 1 1 2 1 1 1 1 2 1 1 1 3 1 2 2 1 1 2 2 4 1 1 4 2 2 1 1 1 2 1 1\n[1962] 2 1 2 2 4 2 2 2 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 1 1 1 1 2 1 1 4\n[1999] 1 1 2 1 1 1 2 1 1 1 1 4 1 3 1 2 1 1 2 2 1 2 2 4 1 1 2 1 2 2 1 1 1 1 1 3 1\n[2036] 1 1 1 1 1 2 1 2 4 1 4 2 4 1 1 2 1 4 2 1 2 2 2 4 2 1 2 4 1 1 1 1 1 1 1 1 2\n[2073] 1 2 1 1 1 4 4 1 2 1 1 4 2 2 1 1 1 1 4 2 1 2 1 2 1 2 1 2 2 1 1 1 4 4 1 2 2\n[2110] 1 1 1 4 2 1 1 2 2 1 2 4 1 1 1 1 1 1 1 1 2 1 1 2 2 1 4 2 4 1 4 4 1 1 2 1 1\n[2147] 1 2 1 1 2 1 1 1 4 1 1 1 2 4 1 1 4 4 1 4 1 1 1 1 1 2 1 4 2 1 1 1 2 1 1 1 1\n[2184] 1 2 1 4 4 1 2 1 2 1 4 1 1 4 1 1 1 4 1 2 1 1 4 1 2 1 2 1 1 1 2 1 4 2 2 2 1\n[2221] 2 2 2 2 2 1 1 1 4 1 2 4 1 1 1 2 1 4 1 4 1 2 2 4 1 4 1 4 4 1 1 2 1 1 2 1 1\n[2258] 2 4 1 1 2 1 1 1 4 2 1 4 1 1 4 1 1 1 2 2 2 1 1 1 1 3 1 1 1 1 1 1 1 2 1 1 1\n[2295] 1 2 4 1 4 1 4 2 4 4 2 1 1 1 4 2 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 4 1 1 1 1\n[2332] 1 2 1 2 1 2 2 1 1 1 1 3 1 1 1 1 1 2 2 1 2 1 4 1 2 2 1 2 2 2 4 1 2 1 1 2 1\n[2369] 2 1 1 1 1 3 1 4 4 1 1 1 2 1 1 2 2 4 2 1 1 1 4 1 2 4 1 1 3 2 2 1 4 4 4 1 1\n[2406] 1 2 4 2 2 4 1 1 2 2 3 2 1 1 2 4 1 1 2 1 1 4 1 2 4 1 4 1 1 2 1 1 4 2 1 1 2\n[2443] 1 2 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 4 4 1 1 2 2 2 1 1 1 1 1 1 2 2 2 4\n[2480] 4 1 2 1 1 1 4 4 2 1 4 4 2 1 2 1 4 1 2 1 1 1 2 1 1 3 3 4 1 2 1 1 4 1 1 1 1\n[2517] 2 2 3 4 1 1 2 1 1 1 2 2 1 2 4 1 4 2 4 1 1 1 2 1 4 1 2 1 4 1 1 1 1 1 2 1 2\n[2554] 1 1 1 4 1 1 4 1 1 1 1 4 1 1 1 1 2 2 1 2 1 1 4 1 1 1 3 3 1 1 4 2 4 4 2 1 1\n[2591] 2 1 4 1 1 4 1 2 1 2 2 2 1 4 2 2 2 1 2 4 4 1 4 1 2 1 4 4 1 4 3 2 1 2 1 2 1\n[2628] 1 1 4 1 2 1 1 1 2 1 1 4 4 1 4 1 4 1 2 2 1 1 1 1 1 1 1 1 4 1 1 4 2 4 2 1 1\n[2665] 1 2 1 4 4 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 4 2 2 2 1 1 1 1 1 2 1\n[2702] 2 4 2 2 1 4 1 2 1 1 2 4 1 1 2 4 1 4 1 1 1 2 2 1 1 2 4 2 1 1 1 1 1 1 1 1 4\n[2739] 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 4 1 4 4 4 4\n[2776] 2 1 1 1 1 1 1 1 1 1 4 1 2 1 2 4 1 4 1 2 1 1 4 1 1 4 1 1 1 1 2 2 2 1 1 4 1\n[2813] 4 4 1 2 1 1 2 2 4 1 4 1 2 2 4 2 2 4 2 1 4 1 1 1 1 2 4 1 1 2 1 1 2 2 4 1 4\n[2850] 4 2 4 2 1 2 1 1 1 1 1 1 2 2 4 1 1 1 2 1 4 4 1 4 1 1 2 1 1 1 4 3 2 1 1 4 2\n[2887] 1 1 2 1 1 2 1 4 1 1 1 4 1 1 2 2 1 1 1 2 1 1 2 2 4 1 1 4 1 1 4 1 1 4 1 2 1\n[2924] 3 1 4 2 3 1 1 2 1 1 1 4 1 1 1 2 2 2 4 2 2 1 3 1 1 2 2 1 2 1 1 1 4 1 2 1 1\n[2961] 2 1 4 1 4 1 1 1 2 2 1 2 2 1 1 2 1 1 2 1 1 4 4 1 4 1 1 1 1 1 1 2 2 4 1 1 1\n[2998] 2 1 1 4 2 2 1 4 2 2 1 4 2 4 2 2 1 2 1 1 4 2 1 2 2 1 1 2 2 4 1 1 2 1 1 1 1\n[3035] 2 4 1 1 2 2 1 1 3 1 1 1 4 4 1 1 2 2 2 1 4 2 2 1 1 2 1 4 1 1 1 1 2 1 2 1 2\n[3072] 3 1 1 1 1 1 4 1 1 2 2 2 1 1 1 2 1 2 2 1 2 1 2 1 1 2 1 4 1 1 4 4 1 2 1 4 1\n[3109] 4 4 2 2 4 1 1 1 4 4 2 2 1 2 4 1 2 1 1 2 1 1 2 2 2 2 3 4 1 1 1 1 1 4 4 1 1\n[3146] 1 1 1 1 1 2 2 2 1 1 2 2 1 1 1 1 1 1 2 1 1 2 4 2 2 4 4 1 2 2 1 4 4 1 2 1 1\n[3183] 4 2 1 4 1 1 1 2 1 1 4 1 1 4 4 1 4 1 2 1 1 1 2 2 1 2 2 1 2 1 1 1 4 4 2 2 1\n[3220] 4 4 1 1 1 1 2 2 1 3 4 1 1 1 1 2 1 1 2 2 2 2 1 1 1 1 2 2 1 4 2 1 2 4 2 1 1\n[3257] 1 1 4 4 2 4 1 1 1 1 1 4 2 1 1 4 4 1 2 2 4 2 2 1 1 1 1 4 2 3 4 1 1 2 2 1 1\n[3294] 2 2 1 2 1 2 1 4 1 4 4 1 2 2 2 2 2 4 1 4 1 2 2 1 2 1 1 4 1 2 2 1 1 1 4 2 1\n[3331] 1 1 1 4 1 2 2 2 4 1 1 2 1 2 1 1 2 1 2 4 4 2 1 2 2 1 2 2 2 4 1 4 1 1 4 1 2\n[3368] 4 1 1 2 1 4 2 1 1 3 2 1 1 1 4 4 1 1 2 4 4 2 4 2 2 4 1 4 2 1 4 2 1 2 1 4 1\n[3405] 2 4 1 1 1 1 4 2 2 1 2 1 4 1 1 2 1 4 1 2 1 1 4 4 4 4 1 1 4 1 2 1 2 1 2 1 4\n[3442] 2 1 2 1 1 1 3 1 2 1 1 3 4 2 4 4 1 3 2 4 2 3 1 3 2 2 1 4 4 1 1 4 2 3 4 2 1\n[3479] 2 1 1 2 2 4 2 4 1 1 1 2 1 1 4 2 1 4 1 1 1 4 4 4 1 2 1 1 2 3 2 1 2 4 2 1 4\n[3516] 4 1 4 1 2 1 1 4 1 1 1 2 4 1 2 4 4 2 2 1 2 1 1 2 1 2 2 1 4 4 2 1 1 4 4 1 2\n[3553] 1 2 1 2 2 2 1 2 3 4 1 2 1 2 1 2 2 4 1 1 1 1 2 1 2 4 4 2 4 1 2 1 1 1 2 1 2\n[3590] 1 2 1 4 1 2 2 2 2 1 1 2 1 1 4 1 2 2 2 1 2 4 2 4 1 4 1 1 1 1 1 2 3 1 4 1 1\n[3627] 4 1 1 1 4 2 4 4 4 1 2 4 4 4 4 4 4 1 2 4 1 4 1 1 3 3 2 1 3 2 1 2 1 1 4 1 4\n[3664] 4 2 4 4 3 2 1 2 2 1 4 1 2 4 1 1 1 1 4 4 4 1 4 1 1 4 1 4 4 4 1 4 1 4 2 2 3\n[3701] 3 3 1 4 2 1 1 1 2 2 2 4 2 4 4 1 4 1 4 1 1 4 4 2 1 1 1 4 4 1 4 4 2 4 4 1 2\n[3738] 2 1 4 2 1 2 2 4 4 2 1 2 2 1 2 4 2 1 4 4 2 4 2 2 1 4 2 1 2 2 2 1 2 1 1 1 1\n[3775] 1 4 1 1 4 2 1 1 2 4 2 1 2 1 1 1 4 2 2 1 4 1 2 4 1 4 4 2 2 1 1 1 4 4 2 1 2\n[3812] 1 2 1 4 2 2 2 2 4 4 4 2 2 1 2 1 4 1 2 1 4 4 4 1 4 4 4 2 2 2 1 1 1 4 4 2 4\n[3849] 2 1 2 4 4 4 2 3 1 1 2 2 1 4 2 4 2 1 1 3 3 4 4 2 3 4 3 4 3 2 1 4 1 4 2 1 2\n[3886] 1 1 1 4 2 4 2 3 2 2 1 1 1 2 4 4 4 4 2 2 4 1 1 1 2 4 4 1 2 1 4 1 4 2 4 2 4\n[3923] 2 2 2 2 1 2 1 2 4 2 1 2 2 1 1 1 4 1 1 2 4 1 4 2 2 1 1 1 2 4 4 1 1 4 4 4 2\n[3960] 1 4 2 3 2 4 1 2 2 1 1 3 4 1 3 4 2 1 4 2 4 2 4 4 4 4 4 4 4 4 1 2 2 1 2 2 2\n[3997] 1 2 4 2 2 4 2 2 1 1 2 1 2 3 2 1 4 4 4 2 2 2 1 1 1 3 4 1 2 4 4 4 1 1 2 4 4\n[4034] 2 1 4 2 2 3 1 2 2 2 4 2 2 1 2 4 2 4 4 1 2 2 1 4 1 1 1 2 2 2 4 2 2 1 1 2 4\n[4071] 2 4 2 4 2 4 2 4 4 2 2 2 1 2 1 2 2 4 4 2 1 1 1 1 2 4 2 4 2 1 2 4 4 2 2 4 2\n[4108] 2 4 4 2 4 4 2 4 3 2 1 2 2 2 2 2 4 2 3 4 4 2 4 2 4 4 2 4 1 2 4 4 2 2 1 4 4\n[4145] 1 2 1 2 1 2 2 2 2 2 4 2 4 2 2 4 1 2 2 1 3 3 1 1 2 2 2 1 2 1 2 2 4 4 4 3 1\n[4182] 2 4 4 4 4 1 4 4 2 4 4 2 1 2 2 2 3 2 3 3 2 4 4 3 1 1 2 1 2 2 2 4 3 1 2 1 2\n[4219] 2 4 2 4 4 4 4 1 4 4 3 4 4 4 1 2 1 3 4 4 3 2 4 4 2 4 3 2 2 1 2 2 4 4 2 3 2\n[4256] 2 2 4 2 2 4 2 4 2 2 2 1 3 2 4 1 3 4 4 4 2 1 2 2 4 1 2 4 1 1 4 1 4 2 4 3 3\n[4293] 2 4 2 4 2 2 1 1 4 1 1 2 4 4 1 1 4 2 2 1 1 2 1 1 4 2 2 2 1 2 4 3 3 2 2 2 1\n[4330] 1 1 1 1 2 1 2 4 2 1 1 2 2 1 4 2 4 4 2 1 1 1 2 4 2 2 1 2 2 4 2 4 1 4 4 2 4\n[4367] 2 2 4 2 3 1 1 2 1 4 2 4 2 2 2 4 2 2 3 4 4 1 1 4 4 2 4 4 3 1 4 4 2 4 4 2 1\n[4404] 4 2 1 1 2 4 1 4 2 1 2 2 4 4 2 3 4 4 4 2 2 2 2 3 1 2 4 2 4 2 2 1 4 2 4 2 4\n[4441] 4 2 2 2 4 4 2 4 4 4 2 4 1 2 4 3 4 2 1 4 1 2 2 1 1 2 1 1 1 2 2 1 4 4 4 4 2\n[4478] 4 4 1 2 4 4 1 1 2 2 4 2 2 1 2 2 2 2 4 4 1 4 1 2 4 2 1 2 4 2 2 1 2 2 1 1 1\n[4515] 2 1 2 2 4 4 4 2 4 4 2 4 4 2 1 1 4 1 4 4 2 2 2 1 2 1 2 4 1 4 4 4 1 1 2 2 1\n[4552] 2 1 4 4 1 1 1 4 1 4 2 4 3 2 2 4 4 4 2 4 4 1 2 1 2 4 1 1 1 4 4 4 2 2 1 1 4\n[4589] 2 2 4 2 2 1 2 4 1 4 1 2 3 2 2 4 1 4 2 4 4 4 1 4 4 4 2 2 3 4 1 2 4 2 1 2 4\n[4626] 3 1 1 2 4 2 4 4 4 2 2 2 4 1 1 4 4 1 1 4 2 3 2 2 1 1 2 2 2 2 1 2 4 1 3 2 2\n[4663] 1 2 3 2 4 1 1 1 1 4 1 4 4 2 2 4 1 1 2 1 1 1 4 4 4 4 4 4 4 3 4 4 1 1 4 1 4\n[4700] 4 1 1 2 1 2 4 1 2 4 2 4 4 1 4 2 1 2 1 2 4 2 4 2 1 4 1 2 3 1 2 4 2 1 1 1 4\n[4737] 4 1 2 4 3 4 1 1 2 2 4 2 2 2 4 4 1 1 1 4 1 2 4 1 3 1 4 1 4 1 4 1 2 2 2 4 2\n[4774] 4 1 1 3 4 2 1 1 4 4 4 2 2 4 1 3 4 2 4 4 4 4 4 2 2 4 1 1 3 4 1 2 1 1 4 4 2\n[4811] 4 4 4 4 2 2 4 4 2 1 1 1 1 1 2 4 1 4 1 1 1 1 2 2 2 4 4 1 4 3 4 1 4 4 2 2 1\n[4848] 1 2 4 1 1 4 1 2 1 4 1 2 4 1 1 1 3 1 3 4 4 1 2 4 3 2 1 2 2 1 1 4 1 1 2 4 2\n[4885] 2 1 2 4 1 2 2 4 4 3 1 1 1 1 4 4 4 1 1 2 2 4 1 1 1 1 1 1 1 4 1 1 4 4 4 2 1\n[4922] 3 1 1 1 1 4 4 2 1 4 1 1 4 4 1 1 2 1 1 1 3 4 3 2 1 2 4 4 4 1 1 1 3 1 2 4 1\n[4959] 4 1 2 1 1 2 1 4 2 2 1 2 2 1 1 4 4 2 1 4 4 1 4 1 1 4 1 1 4 2 1 4 1 4 4 2 4\n[4996] 4 2 4 4 2 1 1 4 4 1 4 2 1 1 2 1 4 4 3 4 1 1 1 2 1 2 4 1 4 1 1 1 1 3 4 4 2\n[5033] 1 2 2 1 1 4 4 1 1 4 2 2 2 1 3 1 2 4 4 4 1 1 4 4 4 2 1 2 2 1 4 2 1 1 1 1 1\n[5070] 2 1 4 3 4 2 2 4 2 1 4 4 1 2 4 4 2 4 2 4 4 2 1 3 2 1 4 4 4 2 1 3 4 1 3 1 1\n[5107] 4 4 1 1 1 4 4 1 2 2 3 2 4 1 1 2 4 1 1 2 4 4 2 2 2 4 2 4 1 1 1 2 1 1 4 4 1\n[5144] 4 1 4 4 4 3 2 1 4 1 4 2 1 4 2 2 1 2 4 4 2 1 2 2 2 2 1 2 1 2 4 4 1 4 1 1 4\n[5181] 2 1 1 2 1 1 1 4 3 4 3 1 2 1 1 4 2 2 4 3 4 1 4 4 1 4 1 1 4 1 1 1 2 2 4 2 2\n[5218] 1 4 1 4 4 1 1 4 3 1 4 1 1 1 4 4 1 2 4 1 4 2 2 4 1 4 1 4 4 1 2 4 1 4 3 3 1\n[5255] 1 4 1 1 2 4 1 4 1 1 1 4 4 1 1 2 4 3 1 4 2 1 2 4 4 1 1 3 2 4 1 4 4 1 2 2 4\n[5292] 1 4 4 4 4 2 2 4 1 1 2 1 1 4 1 2 1 2 4 4 1 4 2 4 4 4 4 3 1 4 4 2 2 4 4 4 2\n[5329] 1 3 1 1 4 1 2 1 4 2 4 2 1 4 1 2 2 1 4 4 4 2 1 1 4 2 4 1 4 1 4 1 4 4 4 1 1\n[5366] 2 2 4 4 1 1 1 1 4 1 4 4 2 2 2 1 2 4 2 1 3 1 4 4 4 2 4 2 3 4 4 4 2 2 2 1 1\n[5403] 1 1 2 1 2 1 4 4 1 1 2 4 4 1 2 2 1 4 2 2 1 4 1 2 1 2 1 4 4 2 2 4 2 2 1 4 1\n[5440] 4 1 1 4 4 1 1 2 1 1 1 1 4 4 1 1 4 1 4 4 4 1 1 1 4 4 4 1 2 2 2 2 4 4 2 2 2\n[5477] 4 4 1 1 2 2 2 1 2 1 1 2 4 4 4 1 4 1 2 1 2 1 4 1 2 4 4 4 2 4 2 2 1 2 2 4 4\n[5514] 4 4 4 2 4 1 4 1 4 4 2 2 1 3 4 4 1 1 1 4 4 4 4 2 4 2 4 4 4 4 4 1 4 3 4 3 4\n[5551] 4 2 1 1 1 1 4 2 1 1 4 4 1 2 2 4 1 4 4 1 1 4 4 4 4 2 4 1 4 2 4 4 1 1 4 3 3\n[5588] 4 4 4 4 1 4 3 1 4 2 2 2 1 4 1 2 2 4 2 4 2 4 3 4 1 4 4 1 4 1 1 4 4 4 4 3 4\n[5625] 1 2 4 4 4 2 4 4 4 2 4 1 4 1 2 4 4 4 2 3 4 1 4 4 1 1 1 1 4 1 4 2 4 2 1 1 4\n[5662] 4 1 1 4 1 4 1 4 1 4 2 4 1 4 1 2 4 4 2 4 4 4 4 3 4 4 4 2 1 3 4 4 1 2 2 1 4\n[5699] 4 4 2 4 4 4 4 4 4 4 1 4 2 1 1 4 4 1 4 4 1 4 3 2 1 4 2 3 1 2 4 1 4 1 1 4 4\n[5736] 4 4 4 4 4 4 1 4 4 1 1 4 2 2 4 1 4 4 4 4 1 4 4 1 4 4 4 4 4 2 1 4 1 4 1 4 4\n[5773] 3 1 4 4 4 1 1 2 2 3 4 4 4 4 4 4 4 3 4 4 2 3 3 3 4 4 1 1 2 4 2 2 4 4 3 4 1\n[5810] 1 2 4 2 1 1 4 4 4 4 1 3 4 4 4 1 4 1 4 3 1 3 4 1 2 1 4 4 4 2 4 4 4 4 4 1 1\n[5847] 4 1 4 3 2 4 4 4 4 2 4 2 2 1 4 4 4 4 1 2 4 4 4 2 1 4 4 1 2 1 4 4 3 2 1 3 2\n[5884] 1 4 3 4 1 2 4 2 1 4 1 1 4 2 3 4 1 1 4 4 4 1 2 2 4 1 4 3 1 4 1 4 4 4 4 4 4\n[5921] 4 1 3 3 1 1 4 1 4 4 2 1 4 4 1 3 3 1 4 4 1 4 1 2 4 4 2 1 3 4 4 4 1 1 4 4 2\n[5958] 3 1 1 4 4 3 4 1 4 1 4 2 4 4 4 1 4 2 3 4 1 2 4 1 4 3 1 1 4 3 1 3 2 4 2 4 4\n[5995] 4 4 4 1 4 2 2 1 4 2 4 4 4 4 4 1 1 1 4 2 4 3 2 4 4 4 1 4 4 2 4 2 3 2 1 3 3\n[6032] 4 1 1 1 3 4 4 1 1 1 4 4 1 4 4 4 4 4 1 4 4 4 4 2 4 1 4 3 2 3 4 4 4 4 4 4 2\n[6069] 4 4 1 1 4 4 1 1 4 4 4 4 4 1 3 4 4 4 4 1 2 4 4 4 4 4 4 4 4 1 4 4 4 2 1 4 3\n[6106] 4 2 4 4 4 2 4 4 4 3 2 4 4 4 4 4 1 4 4 4 3 1 4 2 4 4 2 4 4 1 4 2 4 4 2 4 4\n[6143] 4 3 4 1 1 4 4 1 4 4 1 4 4 4 1 2 4 4 2 1 3 4 4 4 2 2 4 1 4 1 4 4 4 3 3 3 1\n[6180] 1 4 4 2 1 4 4 4 3 1 1 3 3 4 2 4 4 4 1 2 4 4 4 1 1 2 2 4 2 2 2 4 1 3 4 4 4\n[6217] 4 1 2 1 1 1 1 1 3 4 1 3 4 4 4 3 2 4 4 2 3 4 2 1 1 3 2 4 4 4 4 2 4 3 4 2 4\n[6254] 3 2 2 4 4 1 2 4 4 4 4 4 4 3 4 4 4 3 2 4 2 1 4 4 4 4 4 4 2 4 2 2 4 4 2 4 4\n[6291] 4 2 4 1 3 4 4 1 2 4 2 2 2 4 2 4 4 4 4 4 4 4 4 4 3 4 4 4 2 1 2 1 2 3 3 4 4\n[6328] 4 1 1 4 4 4 4 4 4 1 4 1 4 4 1 1 4 2 4 2 1 2 4 4 3 1 4 4 4 4 2 2 4 1 2 1 2\n[6365] 4 4 4 4 4 2 1 4 4 1 4 4 4 4 2 1 4 4 2 4 1 2 4 4 4 4 4 4 4 2 4 4 1 3 2 2 4\n[6402] 4 4 3 1 3 4 2 1 4 2 4 4 1 3 2 4 4 2 4 4 2 2 4 4 4 2 1 4 2 1 1 4 1 3 2 2 1\n[6439] 3 4 3 4 2 1 1 4 2 4 4 4 2 4 4 3 4 4 2 2 3 1 4 2 4 2 2 4 4 2 1 1 3 4 4 4 1\n[6476] 2 3 4 1 3 4 4 1 3 4 1 2 2 1 2 4 2 4 4 2 4 2 2 3 2 4 4 2 4 2 4 2 2 2 4 3 2\n[6513] 1 2 4 4 2 2 4 4 4 2 4 1 4 2 2 4 4 2 3 4 2 2 2 4 1 4 4 4 2 2 1 1 2 4 4 2 4\n[6550] 4 2 1 3 3 2 2 4 2 1 1 1 4 2 4 4 1 3 4 4 4 4 1 4 1 2 1 4 4 4 4 1 2 4 4 1 4\n[6587] 4 4 4 4 4 2 2 2 3 4 3 2 4 4 1 4 4 4 4 4 4 2 2 3 4 2 1 2 4 4 2 2 3 4 1 2 2\n[6624] 4 2 2 4 4 4 2 2 2 4 4 2 4 3 2 2 4 4 2 4 3 3 3 4 4 1 4 4 2 2 1 2 3 2 2 2 4\n[6661] 4 2 4 1 4 1 4 2 4 2 1 4 4 4 4 4 2 2 4 3 4 2 2 4 2 2 2 4 4 2 4 4 2 2 1 4 3\n[6698] 1 4 4 4 1 4 4 4 2 3 4 4 4 4 1 4 2 4 2 1 4 4 4 3 4 4 4 3 4 4 4 1 4 4 1 4 1\n[6735] 1 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[6772] 3 3 3 3 3 3 3 3 3 3 3 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6809] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6846] 1 2 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6883] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6920] 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[6957] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4\n[6994] 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7031] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 2 4\n[7068] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[7105] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4\n[7142] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7179] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7216] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7253] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7290] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4\n[7327] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7364] 2 4 4 4 2 4 4 4 4 4 4 4 4 2 2 4 4 4 4 4 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7401] 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7438] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7475] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7512] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7549] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7586] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7623] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7660] 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 2\n[7697] 2 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 2\n[7734] 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7771] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7808] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7845] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7882] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[7919] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7956] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[7993] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8030] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[8067] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8104] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8141] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1\n[8178] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8215] 4 4 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[8252] 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8289] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8326] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8363] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8400] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8437] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8474] 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8511] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8548] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8585] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8622] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n[8659] 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[8696] 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n[8733] 3 3 3 3 3 3 3 3 4 2 2 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2\n[8770] 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[8807] 3 3 3 3 3 3 3 3 3 3\n\n# #Visualizing clusters \nclusplot(FitData2[,6:7],\n         kmeans$cluster,\n         lines = 0,\n         shade = TRUE,\n         color = TRUE,\n         labels = 2,\n         plotchar = FALSE,\n         span = TRUE,\n         main = paste(\"Cluster of data\"),\n         xlab = '',\n         ylab = '')\nlegend(\"topleft\", legend=c(\"Cluster 1\", \"Cluster 2\", \"Cluster 3\", \"Cluster 4\"), col = c(\"blue\", \"red\", \"purple\",\"green\"), lty= 1:2, cex = 0.8)"
  },
  {
    "objectID": "posts/Classification/index.html",
    "href": "posts/Classification/index.html",
    "title": "Clssification",
    "section": "",
    "text": "In my classification code, I employed the k-Nearest Neighbors (kNN) algorithm to categorize instances within my data set. The kNN method is a simple yet effective algorithm that classifies data points based on the majority class of their k nearest neighbors in the feature space.\nInitially, I preprocessed the data, handling any missing values or normalizing features if necessary. Then, I split the data set into training and testing sets to evaluate the model’s performance. After selecting an appropriate value for k, the number of neighbors to consider, I trained the kNN classifier on the training data. During the classification phase, the algorithm examined the features of a test instance and identified its k nearest neighbors based on a chosen distance metric. The class most prevalent among these neighbors was assigned to the test instance. Finally, I assessed the model’s accuracy and other relevant metrics on the testing set to gauge its performance. The flexibility and simplicity of the kNN algorithm made it a suitable choice for classifying instances in my data set, providing a practical and interpretable solution for the given classification tasks.\n\n                   # Classification\n# Install and load necessary packages\n#if (!requireNamespace(\"class\", quietly = TRUE)) {\n # install.packages(\"class\")\n#}\n#if (!requireNamespace(\"caret\", quietly = TRUE)) {\n # install.packages(\"caret\")\n#}\n#if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n # install.packages(\"ggplot2\")\n#}\n#if (!requireNamespace(\"PRROC\", quietly = TRUE)) {\n # install.packages(\"PRROC\")\n#}\n\nlibrary(pROC)\n\nWarning: package 'pROC' was built under R version 4.2.3\n\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nlibrary(PRROC)\n\nWarning: package 'PRROC' was built under R version 4.2.3\n\nlibrary(class)\n\nWarning: package 'class' was built under R version 4.2.3\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.2.3\n\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nLoading required package: lattice\n\nlibrary(ggplot2)\n\n# Read in data\nFitData2<-read.csv('Book3.csv') \n\n#looking at the data\nnames(FitData2)\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\n# Split the dataset into training and testing sets\nset.seed(123)\nsplitIndex <- createDataPartition(FitData2$LaneCount, p = 0.7, list = FALSE)\ntrain_data <- FitData2[splitIndex, ]\ntest_data <- FitData2[-splitIndex, ]\n\n# Define the number of neighbors (k) for the KNN model\nk <- 9\n\n# Train the KNN model\nknn_model <- knn(train = train_data[, 1:4], test = test_data[, 1:4], cl = train_data$LaneCount, k = k)\n\n# Create a confusion matrix\nconf_matrix <- confusionMatrix(knn_model, as.factor(test_data$LaneCount))\n\n# Display the confusion matrix\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5\n         1    5    4    0    0    0\n         2    8 1413   92   14   12\n         3    2   64  706   12    0\n         4    0   32   15  242    0\n         5    0    2    0    0   21\n\nOverall Statistics\n                                          \n               Accuracy : 0.9028          \n                 95% CI : (0.8909, 0.9138)\n    No Information Rate : 0.573           \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8277          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5\nSensitivity          0.333333   0.9327   0.8684  0.90299 0.636364\nSpecificity          0.998479   0.8884   0.9574  0.98022 0.999234\nPos Pred Value       0.555556   0.9181   0.9005  0.83737 0.913043\nNeg Pred Value       0.996205   0.9077   0.9425  0.98896 0.995422\nPrevalence           0.005673   0.5730   0.3075  0.10136 0.012481\nDetection Rate       0.001891   0.5344   0.2670  0.09153 0.007943\nDetection Prevalence 0.003404   0.5821   0.2965  0.10930 0.008699\nBalanced Accuracy    0.665906   0.9105   0.9129  0.94160 0.817799\n\n# Visualize the confusion matrix\n#png(file=\"cmplot.png\")\nconf_matrix_table <- as.table(conf_matrix)\nggplot(data = as.data.frame(as.table(conf_matrix)), aes(x = Reference, y = Prediction, fill = Freq)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = Freq), vjust = 1) +\n  scale_fill_gradient(low = \"orange\", high = \"darkblue\") +\n  theme_minimal() +\n  labs(title = \"Plot of Confusion Matrix\",\n       x = \"Reference\",\n       y = \"Prediction\",\n       fill = \"Frequency\")\n\n\n\n#dev.off()"
  },
  {
    "objectID": "posts/Classification/index.html#running-code",
    "href": "posts/Classification/index.html#running-code",
    "title": "Post With Code",
    "section": "Running Code",
    "text": "Running Code\n\n                   # Classification\n# Install and load necessary packages\n#if (!requireNamespace(\"class\", quietly = TRUE)) {\n # install.packages(\"class\")\n#}\n#if (!requireNamespace(\"caret\", quietly = TRUE)) {\n # install.packages(\"caret\")\n#}\n#if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n # install.packages(\"ggplot2\")\n#}\n#if (!requireNamespace(\"PRROC\", quietly = TRUE)) {\n # install.packages(\"PRROC\")\n#}\n\nlibrary(pROC)\n\nWarning: package 'pROC' was built under R version 4.2.3\n\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nlibrary(PRROC)\n\nWarning: package 'PRROC' was built under R version 4.2.3\n\nlibrary(class)\n\nWarning: package 'class' was built under R version 4.2.3\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.2.3\n\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nLoading required package: lattice\n\nlibrary(ggplot2)\n\n# Read in data\nFitData2<-read.csv('Book3.csv') \n\n#looking at the data\nnames(FitData2)\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\n# Split the dataset into training and testing sets\nset.seed(123)\nsplitIndex <- createDataPartition(FitData2$LaneCount, p = 0.7, list = FALSE)\ntrain_data <- FitData2[splitIndex, ]\ntest_data <- FitData2[-splitIndex, ]\n\n# Define the number of neighbors (k) for the KNN model\nk <- 9\n\n# Train the KNN model\nknn_model <- knn(train = train_data[, 1:4], test = test_data[, 1:4], cl = train_data$LaneCount, k = k)\n\n# Create a confusion matrix\nconf_matrix <- confusionMatrix(knn_model, as.factor(test_data$LaneCount))\n\n# Display the confusion matrix\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5\n         1    5    4    0    0    0\n         2    8 1413   92   14   12\n         3    2   64  706   12    0\n         4    0   32   15  242    0\n         5    0    2    0    0   21\n\nOverall Statistics\n                                          \n               Accuracy : 0.9028          \n                 95% CI : (0.8909, 0.9138)\n    No Information Rate : 0.573           \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8277          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5\nSensitivity          0.333333   0.9327   0.8684  0.90299 0.636364\nSpecificity          0.998479   0.8884   0.9574  0.98022 0.999234\nPos Pred Value       0.555556   0.9181   0.9005  0.83737 0.913043\nNeg Pred Value       0.996205   0.9077   0.9425  0.98896 0.995422\nPrevalence           0.005673   0.5730   0.3075  0.10136 0.012481\nDetection Rate       0.001891   0.5344   0.2670  0.09153 0.007943\nDetection Prevalence 0.003404   0.5821   0.2965  0.10930 0.008699\nBalanced Accuracy    0.665906   0.9105   0.9129  0.94160 0.817799\n\n# Visualize the confusion matrix\n#png(file=\"cmplot.png\")\nconf_matrix_table <- as.table(conf_matrix)\nggplot(data = as.data.frame(as.table(conf_matrix)), aes(x = Reference, y = Prediction, fill = Freq)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = Freq), vjust = 1) +\n  scale_fill_gradient(low = \"orange\", high = \"darkblue\") +\n  theme_minimal() +\n  labs(title = \"Plot of Confusion Matrix\",\n       x = \"Reference\",\n       y = \"Prediction\",\n       fill = \"Frequency\")\n\n\n\n#dev.off()"
  },
  {
    "objectID": "posts/Outliers Detection/index.html",
    "href": "posts/Outliers Detection/index.html",
    "title": "Outliers Detection",
    "section": "",
    "text": "In my analysis of crash data using average annual daily traffic (AADT), I employed the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm for outlier detection. DBSCAN is particularly effective in identifying clusters of data points that exhibit high density and separating them from less-dense areas, thereby highlighting potential outliers or noise. For this application, each data point represents a specific location on the roadway network, with features including crash counts and AADT values.\nBy employing DBSCAN, I aimed to distinguish regions in the data set where both crash counts and AADT values deviate significantly from the overall patterns. The algorithm classified data points into three categories: core points, which belong to dense regions; border points, which are near dense regions; and noise points, representing potential outliers. This analysis allowed me to pinpoint segments where the relationship between crash incidents and AADT was notably different, potentially indicating areas of higher risk or unexpected safety performance. The identification of these outliers through DBSCAN provided valuable insights into locations where targeted interventions or further investigation might be warranted to improve road safety.\n\n                      # Outliers Detection \n\n# Install and load necessary packages\n#install.packages(\"dbscan\")\nlibrary(dbscan)\n\nWarning: package 'dbscan' was built under R version 4.2.3\n\n\n\nAttaching package: 'dbscan'\n\n\nThe following object is masked from 'package:stats':\n\n    as.dendrogram\n\nlibrary(MASS)\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n# View the structure of the data set (Read in data)\nFitData2<-read.csv('Book3.csv') \nnames(FitData2)#looking at the data\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\n# Generate synthetic data with outliers\nset.seed(123)\ndata <- FitData2[,19:20]\n\n# Perform DBSCAN outlier detection\ndbscan_result <- dbscan(data, eps = 1.5, minPts = 5)\n\n# Visualize the data and outliers using scatterplots\nplot(data[, 1], data[, 2], col = dbscan_result$cluster + 1, pch = 16,\n     main = \"DBSCAN Outlier Detection\", xlab = \"Crash\", ylab = \"Traffic\")\n\n# Add labels for outliers\noutliers <- data[dbscan_result$cluster == 0, ]\ntext(outliers[, 1], outliers[, 2], labels = \"Outlier\", col = \"green\")"
  },
  {
    "objectID": "posts/Outliers Detection/index.html#running-code",
    "href": "posts/Outliers Detection/index.html#running-code",
    "title": "Post With Code",
    "section": "Running Code",
    "text": "Running Code\n\n                      # Outliers Detection \n\n# Install and load necessary packages\n#install.packages(\"dbscan\")\nlibrary(dbscan)\n\nWarning: package 'dbscan' was built under R version 4.2.3\n\n\n\nAttaching package: 'dbscan'\n\n\nThe following object is masked from 'package:stats':\n\n    as.dendrogram\n\nlibrary(MASS)\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n# View the structure of the data set (Read in data)\nFitData2<-read.csv('Book3.csv') \nnames(FitData2)#looking at the data\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\n# Generate synthetic data with outliers\nset.seed(123)\ndata <- FitData2[,19:20]\n\n# Perform DBSCAN outlier detection\ndbscan_result <- dbscan(data, eps = 1.5, minPts = 5)\n\n# Visualize the data and outliers using scatterplots\nplot(data[, 1], data[, 2], col = dbscan_result$cluster + 1, pch = 16,\n     main = \"DBSCAN Outlier Detection\", xlab = \"Crash\", ylab = \"Traffic\")\n\n# Add labels for outliers\noutliers <- data[dbscan_result$cluster == 0, ]\ntext(outliers[, 1], outliers[, 2], labels = \"Outlier\", col = \"green\")"
  },
  {
    "objectID": "posts/Probability Theory/index.html",
    "href": "posts/Probability Theory/index.html",
    "title": "Probability Theory",
    "section": "",
    "text": "In my predictive modeling approach, I utilized a stepwise selection method with a negative binomial model to estimate and forecast the number of crashes based on a diverse set of variables. The data set included features such as mix types, lane counts, roadway geometry, pavement condition, and environmental characteristics, all of which are potential factors influencing the frequency of crashes. The stepwise selection process involved iteratively adding or removing variables to find the subset that contributed most significantly to predicting crash occurrences while avoiding overfitting. The negative binomial model was chosen due to its suitability for count data, especially when dealing with overdispersion, common in crash data.\nI initiated the modeling process by considering the full set of variables and then systematically added or removed predictors based on their statistical significance. This stepwise approach aimed to strike a balance between model simplicity and predictive accuracy. The selected model provided insights into the impact of various road-related factors on crash frequency, allowing for a nuanced understanding of the relationships between mix types, lane counts, roadway geometry, pavement condition, environmental characteristics, and the likelihood of crashes. The negative binomial model’s flexibility in handling count data and the stepwise selection method’s ability to refine the model based on data-driven criteria collectively contributed to a robust predictive framework for estimating crash occurrences in the given context.\n\n                # Probability theory using Negative Binomial\n\n#please find the explanation at the end of the code!\n\n#Install the package for Negative Binomial\nsetwd('C:/Users/behro/OneDrive/Desktop/SS-Infrastructure/project')\n#install.packages(\"lme4\") \nlibrary(MASS)\n#library(ggcorrplot)\n#install.packages(\"ggcorrplot\")\n#install.packages(\"ggplot2\")\n\n# Read in data\nFitData2<-read.csv('Book3.csv') \n\n#looking at the data\nnames(FitData2)\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\nsapply(FitData2, function(x) table(is.na(x)))\n\n        AADT.FALSE     Latitude.FALSE    Longitude.FALSE           yn.FALSE \n              8816               8816               8816               8816 \n     Divided.FALSE    LaneCount.FALSE         DGAC.FALSE        Latex.FALSE \n              8816               8816               8816               8816 \n         SMA.FALSE         PCCP.FALSE          Age.FALSE     Friction.FALSE \n              8816               8816               8816               8816 \n       Macro.FALSE          IRI.FALSE     Gradient.FALSE    Curvature.FALSE \n              8816               8816               8816               8816 \n LatitudeGPS.FALSE LongitudeGps.FALSE        Crash.FALSE       lnAADT.FALSE \n              8816               8816               8816               8816 \n\n# Correlation Matrix\ncormat<- cor(FitData2)\ncormat\n\n                     AADT     Latitude    Longitude            yn     Divided\nAADT          1.000000000  0.382693033  0.336510001 -0.1036752130  0.35229051\nLatitude      0.382693033  1.000000000  0.549169304  0.0867984066  0.07971012\nLongitude     0.336510001  0.549169304  1.000000000  0.0615009111  0.09100533\nyn           -0.103675213  0.086798407  0.061500911  1.0000000000 -0.10401913\nDivided       0.352290506  0.079710125  0.091005327 -0.1040191257  1.00000000\nLaneCount     0.144392325  0.204102326  0.259898519  0.1087742622 -0.42121275\nDGAC         -0.342787046 -0.186630838 -0.267382176  0.1986031579 -0.35249134\nLatex        -0.143490494 -0.217002363 -0.329335117  0.0049419700  0.04027118\nSMA           0.482314027  0.292613391  0.356983572 -0.1982727448  0.29135814\nPCCP         -0.104437562  0.052998652  0.241103815 -0.0237787399  0.11698407\nAge          -0.158760926 -0.024844945  0.158414166 -0.0004544039 -0.05989411\nFriction     -0.415230010 -0.389880287 -0.438834333 -0.1678539143 -0.09097330\nMacro         0.092220941  0.023476717 -0.041446945 -0.0582230520 -0.01326821\nIRI          -0.160528788  0.041491845  0.140259933  0.3264015510 -0.22222393\nGradient      0.005037783 -0.003607073 -0.005207780  0.0036117087  0.01007699\nCurvature     0.061725730  0.010116036 -0.002109046  0.1469357438 -0.02601795\nLatitudeGPS   0.382692421  0.999999967  0.549167479  0.0867951489  0.07970644\nLongitudeGps  0.336512300  0.549168585  0.999999961  0.0615026871  0.09100524\nCrash         0.361690726  0.244032354  0.186330460  0.2336554548  0.15408900\nlnAADT        0.835351570  0.342518127  0.324002405 -0.0195230055  0.40428459\n                LaneCount        DGAC        Latex           SMA         PCCP\nAADT          0.144392325 -0.34278705 -0.143490494  0.4823140266 -0.104437562\nLatitude      0.204102326 -0.18663084 -0.217002363  0.2926133913  0.052998652\nLongitude     0.259898519 -0.26738218 -0.329335117  0.3569835715  0.241103815\nyn            0.108774262  0.19860316  0.004941970 -0.1982727448 -0.023778740\nDivided      -0.421212754 -0.35249134  0.040271179  0.2913581427  0.116984071\nLaneCount     1.000000000 -0.00429124 -0.079532105  0.0817235549 -0.073712310\nDGAC         -0.004291240  1.00000000 -0.298559690 -0.7697597871 -0.224670040\nLatex        -0.079532105 -0.29855969  1.000000000 -0.2254810823 -0.065811237\nSMA           0.081723555 -0.76975979 -0.225481082  1.0000000000 -0.169677440\nPCCP         -0.073712310 -0.22467004 -0.065811237 -0.1696774395  1.000000000\nAge          -0.015097045 -0.05923362 -0.161581052 -0.1334001818  0.650244134\nFriction     -0.174884591  0.21076334  0.243654955 -0.3719020243  0.036211487\nMacro         0.132768160 -0.08099538 -0.080735534  0.1798355619 -0.114403038\nIRI           0.127621155  0.18473958 -0.009695252 -0.2889567507  0.233892002\nGradient     -0.007350165 -0.00110724  0.011015114 -0.0008447454 -0.009595485\nCurvature     0.024597182  0.07032162  0.029959542 -0.0716087422 -0.041406475\nLatitudeGPS   0.204101348 -0.18662624 -0.217004614  0.2926093663  0.052999860\nLongitudeGps  0.259893844 -0.26737941 -0.329337823  0.3569835555  0.241100795\nCrash         0.144932017 -0.01725508 -0.061020210  0.0790970272 -0.060913658\nlnAADT        0.044847392 -0.31190922 -0.095631964  0.4253369237 -0.109064489\n                       Age     Friction         Macro          IRI\nAADT         -0.1587609255 -0.415230010  0.0922209412 -0.160528788\nLatitude     -0.0248449450 -0.389880287  0.0234767171  0.041491845\nLongitude     0.1584141663 -0.438834333 -0.0414469448  0.140259933\nyn           -0.0004544039 -0.167853914 -0.0582230520  0.326401551\nDivided      -0.0598941084 -0.090973297 -0.0132682097 -0.222223926\nLaneCount    -0.0150970455 -0.174884591  0.1327681600  0.127621155\nDGAC         -0.0592336203  0.210763341 -0.0809953807  0.184739579\nLatex        -0.1615810517  0.243654955 -0.0807355339 -0.009695252\nSMA          -0.1334001818 -0.371902024  0.1798355619 -0.288956751\nPCCP          0.6502441336  0.036211487 -0.1144030381  0.233892002\nAge           1.0000000000 -0.004908474  0.0556296414  0.257779550\nFriction     -0.0049084743  1.000000000 -0.0578124559 -0.208562713\nMacro         0.0556296414 -0.057812456  1.0000000000  0.091219056\nIRI           0.2577795499 -0.208562713  0.0912190564  1.000000000\nGradient     -0.0089316816 -0.002515723 -0.0001392182 -0.015133902\nCurvature    -0.0219502445 -0.139511290  0.0257072470  0.204565067\nLatitudeGPS  -0.0248450008 -0.389879453  0.0234781289  0.041493732\nLongitudeGps  0.1584140933 -0.438832739 -0.0414425553  0.140257999\nCrash        -0.0983321348 -0.302675329 -0.0168212158  0.173922828\nlnAADT       -0.1763974925 -0.392309573 -0.0114531822 -0.155893535\n                  Gradient    Curvature  LatitudeGPS LongitudeGps        Crash\nAADT          0.0050377827  0.061725730  0.382692421  0.336512300  0.361690726\nLatitude     -0.0036070735  0.010116036  0.999999967  0.549168585  0.244032354\nLongitude    -0.0052077804 -0.002109046  0.549167479  0.999999961  0.186330460\nyn            0.0036117087  0.146935744  0.086795149  0.061502687  0.233655455\nDivided       0.0100769888 -0.026017952  0.079706439  0.091005243  0.154088999\nLaneCount    -0.0073501646  0.024597182  0.204101348  0.259893844  0.144932017\nDGAC         -0.0011072403  0.070321624 -0.186626245 -0.267379408 -0.017255081\nLatex         0.0110151144  0.029959542 -0.217004614 -0.329337823 -0.061020210\nSMA          -0.0008447454 -0.071608742  0.292609366  0.356983555  0.079097027\nPCCP         -0.0095954854 -0.041406475  0.052999860  0.241100795 -0.060913658\nAge          -0.0089316816 -0.021950245 -0.024845001  0.158414093 -0.098332135\nFriction     -0.0025157234 -0.139511290 -0.389879453 -0.438832739 -0.302675329\nMacro        -0.0001392182  0.025707247  0.023478129 -0.041442555 -0.016821216\nIRI          -0.0151339016  0.204565067  0.041493732  0.140257999  0.173922828\nGradient      1.0000000000 -0.009613057 -0.003608268 -0.005203478 -0.009375788\nCurvature    -0.0096130566  1.000000000  0.010119044 -0.002105554  0.125889418\nLatitudeGPS  -0.0036082680  0.010119044  1.000000000  0.549166759  0.244025290\nLongitudeGps -0.0052034777 -0.002105554  0.549166759  1.000000000  0.186335639\nCrash        -0.0093757875  0.125889418  0.244025290  0.186335639  1.000000000\nlnAADT        0.0066595772  0.043316382  0.342518906  0.324003528  0.302312430\n                   lnAADT\nAADT          0.835351570\nLatitude      0.342518127\nLongitude     0.324002405\nyn           -0.019523006\nDivided       0.404284590\nLaneCount     0.044847392\nDGAC         -0.311909222\nLatex        -0.095631964\nSMA           0.425336924\nPCCP         -0.109064489\nAge          -0.176397492\nFriction     -0.392309573\nMacro        -0.011453182\nIRI          -0.155893535\nGradient      0.006659577\nCurvature     0.043316382\nLatitudeGPS   0.342518906\nLongitudeGps  0.324003528\nCrash         0.302312430\nlnAADT        1.000000000\n\n#Set the reference value for a categorical variable. (NO categorical as I made them binary in the excel file, so I commented)\n FitData2$yn<-as.factor(FitData2$yn)\n FitData2$Divided<-as.factor(FitData2$Divided)\n FitData2$DGAC<-as.factor(FitData2$DGAC)\n FitData2$SMA<-as.factor(FitData2$SMA)\n FitData2$PCCP<-as.factor(FitData2$PCCP)\n FitData2$Latex<-as.factor(FitData2$Latex)\n\n   \n#Create a base model binomial model.  The SPF should always include traffic volume and I must input the natural log conversion of the traffic volume, i.e., ln(AADT).\nbase_model <- glm.nb(Crash ~ lnAADT,data = FitData2)\nfull_modell<-glm.nb(Crash~ lnAADT+ yn + Divided + LaneCount + DGAC + Latex + SMA + PCCP + Age + Friction + Macro + IRI + Gradient + Curvature, data=FitData2)\n\n#Create the full model\nStepWiseFit <- step(base_model,scope = list(lower= base_model,upper= full_modell),direction = 'forward') \n\nStart:  AIC=30177.42\nCrash ~ lnAADT\n\n            Df Deviance   AIC\n+ Friction   1   7207.9 29123\n+ yn         1   7399.3 29315\n+ IRI        1   7825.1 29741\n+ LaneCount  1   7909.9 29825\n+ Curvature  1   8116.7 30032\n+ Divided    1   8120.5 30036\n+ Age        1   8188.1 30104\n+ Latex      1   8202.5 30118\n+ PCCP       1   8241.4 30157\n+ SMA        1   8253.3 30169\n+ Macro      1   8255.9 30172\n+ DGAC       1   8258.4 30174\n<none>           8263.8 30177\n+ Gradient   1   8263.7 30179\n\nStep:  AIC=29051.58\nCrash ~ lnAADT + Friction\n\n            Df Deviance   AIC\n+ yn         1   7511.1 28457\n+ LaneCount  1   7895.0 28841\n+ IRI        1   7922.6 28869\n+ Divided    1   7940.0 28886\n+ Age        1   8014.8 28961\n+ Curvature  1   8023.1 28969\n+ DGAC       1   8070.3 29016\n+ PCCP       1   8087.4 29033\n+ SMA        1   8096.2 29042\n+ Macro      1   8097.5 29043\n+ Latex      1   8100.3 29046\n<none>           8107.7 29052\n+ Gradient   1   8107.7 29054\n\nStep:  AIC=28413.95\nCrash ~ lnAADT + Friction + yn\n\n            Df Deviance   AIC\n+ Divided    1   7936.5 28134\n+ LaneCount  1   8026.4 28224\n+ Age        1   8126.2 28323\n+ Curvature  1   8172.1 28369\n+ SMA        1   8181.1 28378\n+ IRI        1   8190.5 28388\n+ Latex      1   8199.6 28397\n+ PCCP       1   8200.9 28398\n+ DGAC       1   8214.4 28412\n<none>           8218.8 28414\n+ Macro      1   8218.4 28416\n+ Gradient   1   8218.5 28416\n\nStep:  AIC=28130.91\nCrash ~ lnAADT + Friction + yn + Divided\n\n            Df Deviance   AIC\n+ LaneCount  1   7655.2 27669\n+ Age        1   8030.6 28044\n+ IRI        1   8066.6 28080\n+ Curvature  1   8069.9 28083\n+ PCCP       1   8086.9 28100\n+ Latex      1   8091.4 28105\n+ SMA        1   8110.7 28124\n+ DGAC       1   8115.2 28129\n<none>           8119.4 28131\n+ Gradient   1   8118.7 28132\n+ Macro      1   8119.4 28133\n\nStep:  AIC=27650.25\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount\n\n            Df Deviance   AIC\n+ Age        1   8028.9 27570\n+ IRI        1   8033.3 27575\n+ Curvature  1   8061.8 27603\n+ PCCP       1   8089.6 27631\n+ DGAC       1   8091.0 27633\n+ Macro      1   8095.6 27637\n+ Latex      1   8098.4 27640\n<none>           8110.8 27650\n+ SMA        1   8110.2 27652\n+ Gradient   1   8110.6 27652\n\nStep:  AIC=27569.83\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age\n\n            Df Deviance   AIC\n+ IRI        1   8001.2 27467\n+ Curvature  1   8057.8 27523\n+ Latex      1   8082.9 27548\n+ Macro      1   8090.2 27556\n+ DGAC       1   8095.8 27561\n<none>           8106.4 27570\n+ SMA        1   8105.1 27571\n+ PCCP       1   8105.2 27571\n+ Gradient   1   8106.0 27571\n\nStep:  AIC=27464.61\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI\n\n            Df Deviance   AIC\n+ Curvature  1   8127.6 27436\n+ Latex      1   8129.7 27438\n+ Macro      1   8138.0 27447\n+ SMA        1   8155.2 27464\n+ DGAC       1   8155.6 27464\n<none>           8158.0 27465\n+ PCCP       1   8156.7 27465\n+ Gradient   1   8157.7 27466\n\nStep:  AIC=27436.14\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature\n\n           Df Deviance   AIC\n+ Latex     1   8125.0 27408\n+ Macro     1   8132.8 27416\n+ SMA       1   8151.6 27435\n+ DGAC      1   8152.5 27436\n<none>          8154.7 27436\n+ PCCP      1   8154.1 27438\n+ Gradient  1   8154.4 27438\n\nStep:  AIC=27408.4\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature + Latex\n\n           Df Deviance   AIC\n+ Macro     1   8111.6 27385\n<none>          8136.7 27408\n+ SMA       1   8136.2 27410\n+ PCCP      1   8136.2 27410\n+ Gradient  1   8136.4 27410\n+ DGAC      1   8136.5 27410\n\nStep:  AIC=27385.32\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature + Latex + Macro\n\n           Df Deviance   AIC\n+ SMA       1   8127.9 27383\n+ DGAC      1   8129.7 27385\n<none>          8132.2 27385\n+ PCCP      1   8130.5 27386\n+ Gradient  1   8131.9 27387\n\nStep:  AIC=27383.04\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature + Latex + Macro + SMA\n\n           Df Deviance   AIC\n<none>          8120.2 27383\n+ DGAC      1   8119.0 27384\n+ PCCP      1   8119.0 27384\n+ Gradient  1   8119.9 27385\n\nsummary(StepWiseFit)\n\n\nCall:\nglm.nb(formula = Crash ~ lnAADT + Friction + yn + Divided + LaneCount + \n    Age + IRI + Curvature + Latex + Macro + SMA, data = FitData2, \n    init.theta = 0.9268485234, link = log)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7462  -0.9723  -0.5686   0.2126   7.4490  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -2.333449   0.236090  -9.884  < 2e-16 ***\nlnAADT        0.303521   0.014160  21.435  < 2e-16 ***\nFriction     -0.054863   0.002623 -20.915  < 2e-16 ***\nyn1           0.829530   0.036787  22.550  < 2e-16 ***\nDivided1      1.207650   0.050552  23.889  < 2e-16 ***\nLaneCount     0.542440   0.024544  22.100  < 2e-16 ***\nAge          -0.022080   0.002018 -10.943  < 2e-16 ***\nIRI           0.200922   0.020445   9.827  < 2e-16 ***\nCurvature   204.398987  29.403738   6.951 3.62e-12 ***\nLatex1       -0.350783   0.068954  -5.087 3.63e-07 ***\nMacro        -0.471428   0.087670  -5.377 7.56e-08 ***\nSMA1          0.080317   0.039742   2.021   0.0433 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.9268) family taken to be 1)\n\n    Null deviance: 14113.4  on 8815  degrees of freedom\nResidual deviance:  8120.2  on 8804  degrees of freedom\nAIC: 27385\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.9268 \n          Std. Err.:  0.0266 \n\n 2 x log-likelihood:  -27359.0430 \n\nsummary(StepWiseFit)$coefficients\n\n                Estimate   Std. Error    z value      Pr(>|z|)\n(Intercept)  -2.33344930  0.236090474  -9.883708  4.898601e-23\nlnAADT        0.30352129  0.014160144  21.434901 6.316823e-102\nFriction     -0.05486347  0.002623175 -20.914910  3.917635e-97\nyn1           0.82953006  0.036786588  22.549796 1.349053e-112\nDivided1      1.20765000  0.050551760  23.889376 3.949606e-126\nLaneCount     0.54244042  0.024544432  22.100345 3.136613e-108\nAge          -0.02207983  0.002017757 -10.942757  7.197696e-28\nIRI           0.20092202  0.020445238   9.827326  8.586842e-23\nCurvature   204.39898667 29.403737606   6.951463  3.615179e-12\nLatex1       -0.35078254  0.068954031  -5.087194  3.633999e-07\nMacro        -0.47142753  0.087669743  -5.377312  7.560621e-08\nSMA1          0.08031675  0.039741777   2.020965  4.328337e-02\n\n# Create a histogram of predicted counts\nhist(StepWiseFit$fitted.values, \n     main = \"Distribution of Predicted Crash Probabilities\",\n     xlab = \"Predicted Probabilities\", \n     ylab = \"Frequency\",\n          col = \"green\", \n     border = \"black\", \n     breaks = 20)"
  },
  {
    "objectID": "posts/Probability Theory/index.html#running-code",
    "href": "posts/Probability Theory/index.html#running-code",
    "title": "Post With Code",
    "section": "Running Code",
    "text": "Running Code\n\n                # Probability theory using Negative Binomial\n\n#please find the explanation at the end of the code!\n\n#Install the package for Negative Binomial\nsetwd('C:/Users/behro/OneDrive/Desktop/SS-Infrastructure/project')\n#install.packages(\"lme4\") \nlibrary(MASS)\n#library(ggcorrplot)\n#install.packages(\"ggcorrplot\")\n#install.packages(\"ggplot2\")\n\n# Read in data\nFitData2<-read.csv('Book3.csv') \n\n#looking at the data\nnames(FitData2)\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\nsapply(FitData2, function(x) table(is.na(x)))\n\n        AADT.FALSE     Latitude.FALSE    Longitude.FALSE           yn.FALSE \n              8816               8816               8816               8816 \n     Divided.FALSE    LaneCount.FALSE         DGAC.FALSE        Latex.FALSE \n              8816               8816               8816               8816 \n         SMA.FALSE         PCCP.FALSE          Age.FALSE     Friction.FALSE \n              8816               8816               8816               8816 \n       Macro.FALSE          IRI.FALSE     Gradient.FALSE    Curvature.FALSE \n              8816               8816               8816               8816 \n LatitudeGPS.FALSE LongitudeGps.FALSE        Crash.FALSE       lnAADT.FALSE \n              8816               8816               8816               8816 \n\n# Correlation Matrix\ncormat<- cor(FitData2)\ncormat\n\n                     AADT     Latitude    Longitude            yn     Divided\nAADT          1.000000000  0.382693033  0.336510001 -0.1036752130  0.35229051\nLatitude      0.382693033  1.000000000  0.549169304  0.0867984066  0.07971012\nLongitude     0.336510001  0.549169304  1.000000000  0.0615009111  0.09100533\nyn           -0.103675213  0.086798407  0.061500911  1.0000000000 -0.10401913\nDivided       0.352290506  0.079710125  0.091005327 -0.1040191257  1.00000000\nLaneCount     0.144392325  0.204102326  0.259898519  0.1087742622 -0.42121275\nDGAC         -0.342787046 -0.186630838 -0.267382176  0.1986031579 -0.35249134\nLatex        -0.143490494 -0.217002363 -0.329335117  0.0049419700  0.04027118\nSMA           0.482314027  0.292613391  0.356983572 -0.1982727448  0.29135814\nPCCP         -0.104437562  0.052998652  0.241103815 -0.0237787399  0.11698407\nAge          -0.158760926 -0.024844945  0.158414166 -0.0004544039 -0.05989411\nFriction     -0.415230010 -0.389880287 -0.438834333 -0.1678539143 -0.09097330\nMacro         0.092220941  0.023476717 -0.041446945 -0.0582230520 -0.01326821\nIRI          -0.160528788  0.041491845  0.140259933  0.3264015510 -0.22222393\nGradient      0.005037783 -0.003607073 -0.005207780  0.0036117087  0.01007699\nCurvature     0.061725730  0.010116036 -0.002109046  0.1469357438 -0.02601795\nLatitudeGPS   0.382692421  0.999999967  0.549167479  0.0867951489  0.07970644\nLongitudeGps  0.336512300  0.549168585  0.999999961  0.0615026871  0.09100524\nCrash         0.361690726  0.244032354  0.186330460  0.2336554548  0.15408900\nlnAADT        0.835351570  0.342518127  0.324002405 -0.0195230055  0.40428459\n                LaneCount        DGAC        Latex           SMA         PCCP\nAADT          0.144392325 -0.34278705 -0.143490494  0.4823140266 -0.104437562\nLatitude      0.204102326 -0.18663084 -0.217002363  0.2926133913  0.052998652\nLongitude     0.259898519 -0.26738218 -0.329335117  0.3569835715  0.241103815\nyn            0.108774262  0.19860316  0.004941970 -0.1982727448 -0.023778740\nDivided      -0.421212754 -0.35249134  0.040271179  0.2913581427  0.116984071\nLaneCount     1.000000000 -0.00429124 -0.079532105  0.0817235549 -0.073712310\nDGAC         -0.004291240  1.00000000 -0.298559690 -0.7697597871 -0.224670040\nLatex        -0.079532105 -0.29855969  1.000000000 -0.2254810823 -0.065811237\nSMA           0.081723555 -0.76975979 -0.225481082  1.0000000000 -0.169677440\nPCCP         -0.073712310 -0.22467004 -0.065811237 -0.1696774395  1.000000000\nAge          -0.015097045 -0.05923362 -0.161581052 -0.1334001818  0.650244134\nFriction     -0.174884591  0.21076334  0.243654955 -0.3719020243  0.036211487\nMacro         0.132768160 -0.08099538 -0.080735534  0.1798355619 -0.114403038\nIRI           0.127621155  0.18473958 -0.009695252 -0.2889567507  0.233892002\nGradient     -0.007350165 -0.00110724  0.011015114 -0.0008447454 -0.009595485\nCurvature     0.024597182  0.07032162  0.029959542 -0.0716087422 -0.041406475\nLatitudeGPS   0.204101348 -0.18662624 -0.217004614  0.2926093663  0.052999860\nLongitudeGps  0.259893844 -0.26737941 -0.329337823  0.3569835555  0.241100795\nCrash         0.144932017 -0.01725508 -0.061020210  0.0790970272 -0.060913658\nlnAADT        0.044847392 -0.31190922 -0.095631964  0.4253369237 -0.109064489\n                       Age     Friction         Macro          IRI\nAADT         -0.1587609255 -0.415230010  0.0922209412 -0.160528788\nLatitude     -0.0248449450 -0.389880287  0.0234767171  0.041491845\nLongitude     0.1584141663 -0.438834333 -0.0414469448  0.140259933\nyn           -0.0004544039 -0.167853914 -0.0582230520  0.326401551\nDivided      -0.0598941084 -0.090973297 -0.0132682097 -0.222223926\nLaneCount    -0.0150970455 -0.174884591  0.1327681600  0.127621155\nDGAC         -0.0592336203  0.210763341 -0.0809953807  0.184739579\nLatex        -0.1615810517  0.243654955 -0.0807355339 -0.009695252\nSMA          -0.1334001818 -0.371902024  0.1798355619 -0.288956751\nPCCP          0.6502441336  0.036211487 -0.1144030381  0.233892002\nAge           1.0000000000 -0.004908474  0.0556296414  0.257779550\nFriction     -0.0049084743  1.000000000 -0.0578124559 -0.208562713\nMacro         0.0556296414 -0.057812456  1.0000000000  0.091219056\nIRI           0.2577795499 -0.208562713  0.0912190564  1.000000000\nGradient     -0.0089316816 -0.002515723 -0.0001392182 -0.015133902\nCurvature    -0.0219502445 -0.139511290  0.0257072470  0.204565067\nLatitudeGPS  -0.0248450008 -0.389879453  0.0234781289  0.041493732\nLongitudeGps  0.1584140933 -0.438832739 -0.0414425553  0.140257999\nCrash        -0.0983321348 -0.302675329 -0.0168212158  0.173922828\nlnAADT       -0.1763974925 -0.392309573 -0.0114531822 -0.155893535\n                  Gradient    Curvature  LatitudeGPS LongitudeGps        Crash\nAADT          0.0050377827  0.061725730  0.382692421  0.336512300  0.361690726\nLatitude     -0.0036070735  0.010116036  0.999999967  0.549168585  0.244032354\nLongitude    -0.0052077804 -0.002109046  0.549167479  0.999999961  0.186330460\nyn            0.0036117087  0.146935744  0.086795149  0.061502687  0.233655455\nDivided       0.0100769888 -0.026017952  0.079706439  0.091005243  0.154088999\nLaneCount    -0.0073501646  0.024597182  0.204101348  0.259893844  0.144932017\nDGAC         -0.0011072403  0.070321624 -0.186626245 -0.267379408 -0.017255081\nLatex         0.0110151144  0.029959542 -0.217004614 -0.329337823 -0.061020210\nSMA          -0.0008447454 -0.071608742  0.292609366  0.356983555  0.079097027\nPCCP         -0.0095954854 -0.041406475  0.052999860  0.241100795 -0.060913658\nAge          -0.0089316816 -0.021950245 -0.024845001  0.158414093 -0.098332135\nFriction     -0.0025157234 -0.139511290 -0.389879453 -0.438832739 -0.302675329\nMacro        -0.0001392182  0.025707247  0.023478129 -0.041442555 -0.016821216\nIRI          -0.0151339016  0.204565067  0.041493732  0.140257999  0.173922828\nGradient      1.0000000000 -0.009613057 -0.003608268 -0.005203478 -0.009375788\nCurvature    -0.0096130566  1.000000000  0.010119044 -0.002105554  0.125889418\nLatitudeGPS  -0.0036082680  0.010119044  1.000000000  0.549166759  0.244025290\nLongitudeGps -0.0052034777 -0.002105554  0.549166759  1.000000000  0.186335639\nCrash        -0.0093757875  0.125889418  0.244025290  0.186335639  1.000000000\nlnAADT        0.0066595772  0.043316382  0.342518906  0.324003528  0.302312430\n                   lnAADT\nAADT          0.835351570\nLatitude      0.342518127\nLongitude     0.324002405\nyn           -0.019523006\nDivided       0.404284590\nLaneCount     0.044847392\nDGAC         -0.311909222\nLatex        -0.095631964\nSMA           0.425336924\nPCCP         -0.109064489\nAge          -0.176397492\nFriction     -0.392309573\nMacro        -0.011453182\nIRI          -0.155893535\nGradient      0.006659577\nCurvature     0.043316382\nLatitudeGPS   0.342518906\nLongitudeGps  0.324003528\nCrash         0.302312430\nlnAADT        1.000000000\n\n#Set the reference value for a categorical variable. (NO categorical as I made them binary in the excel file, so I commented)\n FitData2$yn<-as.factor(FitData2$yn)\n FitData2$Divided<-as.factor(FitData2$Divided)\n FitData2$DGAC<-as.factor(FitData2$DGAC)\n FitData2$SMA<-as.factor(FitData2$SMA)\n FitData2$PCCP<-as.factor(FitData2$PCCP)\n FitData2$Latex<-as.factor(FitData2$Latex)\n\n   \n#Create a base model binomial model.  The SPF should always include traffic volume and I must input the natural log conversion of the traffic volume, i.e., ln(AADT).\nbase_model <- glm.nb(Crash ~ lnAADT,data = FitData2)\nfull_modell<-glm.nb(Crash~ lnAADT+ yn + Divided + LaneCount + DGAC + Latex + SMA + PCCP + Age + Friction + Macro + IRI + Gradient + Curvature, data=FitData2)\n\n#Create the full model\nStepWiseFit <- step(base_model,scope = list(lower= base_model,upper= full_modell),direction = 'forward') \n\nStart:  AIC=30177.42\nCrash ~ lnAADT\n\n            Df Deviance   AIC\n+ Friction   1   7207.9 29123\n+ yn         1   7399.3 29315\n+ IRI        1   7825.1 29741\n+ LaneCount  1   7909.9 29825\n+ Curvature  1   8116.7 30032\n+ Divided    1   8120.5 30036\n+ Age        1   8188.1 30104\n+ Latex      1   8202.5 30118\n+ PCCP       1   8241.4 30157\n+ SMA        1   8253.3 30169\n+ Macro      1   8255.9 30172\n+ DGAC       1   8258.4 30174\n<none>           8263.8 30177\n+ Gradient   1   8263.7 30179\n\nStep:  AIC=29051.58\nCrash ~ lnAADT + Friction\n\n            Df Deviance   AIC\n+ yn         1   7511.1 28457\n+ LaneCount  1   7895.0 28841\n+ IRI        1   7922.6 28869\n+ Divided    1   7940.0 28886\n+ Age        1   8014.8 28961\n+ Curvature  1   8023.1 28969\n+ DGAC       1   8070.3 29016\n+ PCCP       1   8087.4 29033\n+ SMA        1   8096.2 29042\n+ Macro      1   8097.5 29043\n+ Latex      1   8100.3 29046\n<none>           8107.7 29052\n+ Gradient   1   8107.7 29054\n\nStep:  AIC=28413.95\nCrash ~ lnAADT + Friction + yn\n\n            Df Deviance   AIC\n+ Divided    1   7936.5 28134\n+ LaneCount  1   8026.4 28224\n+ Age        1   8126.2 28323\n+ Curvature  1   8172.1 28369\n+ SMA        1   8181.1 28378\n+ IRI        1   8190.5 28388\n+ Latex      1   8199.6 28397\n+ PCCP       1   8200.9 28398\n+ DGAC       1   8214.4 28412\n<none>           8218.8 28414\n+ Macro      1   8218.4 28416\n+ Gradient   1   8218.5 28416\n\nStep:  AIC=28130.91\nCrash ~ lnAADT + Friction + yn + Divided\n\n            Df Deviance   AIC\n+ LaneCount  1   7655.2 27669\n+ Age        1   8030.6 28044\n+ IRI        1   8066.6 28080\n+ Curvature  1   8069.9 28083\n+ PCCP       1   8086.9 28100\n+ Latex      1   8091.4 28105\n+ SMA        1   8110.7 28124\n+ DGAC       1   8115.2 28129\n<none>           8119.4 28131\n+ Gradient   1   8118.7 28132\n+ Macro      1   8119.4 28133\n\nStep:  AIC=27650.25\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount\n\n            Df Deviance   AIC\n+ Age        1   8028.9 27570\n+ IRI        1   8033.3 27575\n+ Curvature  1   8061.8 27603\n+ PCCP       1   8089.6 27631\n+ DGAC       1   8091.0 27633\n+ Macro      1   8095.6 27637\n+ Latex      1   8098.4 27640\n<none>           8110.8 27650\n+ SMA        1   8110.2 27652\n+ Gradient   1   8110.6 27652\n\nStep:  AIC=27569.83\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age\n\n            Df Deviance   AIC\n+ IRI        1   8001.2 27467\n+ Curvature  1   8057.8 27523\n+ Latex      1   8082.9 27548\n+ Macro      1   8090.2 27556\n+ DGAC       1   8095.8 27561\n<none>           8106.4 27570\n+ SMA        1   8105.1 27571\n+ PCCP       1   8105.2 27571\n+ Gradient   1   8106.0 27571\n\nStep:  AIC=27464.61\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI\n\n            Df Deviance   AIC\n+ Curvature  1   8127.6 27436\n+ Latex      1   8129.7 27438\n+ Macro      1   8138.0 27447\n+ SMA        1   8155.2 27464\n+ DGAC       1   8155.6 27464\n<none>           8158.0 27465\n+ PCCP       1   8156.7 27465\n+ Gradient   1   8157.7 27466\n\nStep:  AIC=27436.14\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature\n\n           Df Deviance   AIC\n+ Latex     1   8125.0 27408\n+ Macro     1   8132.8 27416\n+ SMA       1   8151.6 27435\n+ DGAC      1   8152.5 27436\n<none>          8154.7 27436\n+ PCCP      1   8154.1 27438\n+ Gradient  1   8154.4 27438\n\nStep:  AIC=27408.4\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature + Latex\n\n           Df Deviance   AIC\n+ Macro     1   8111.6 27385\n<none>          8136.7 27408\n+ SMA       1   8136.2 27410\n+ PCCP      1   8136.2 27410\n+ Gradient  1   8136.4 27410\n+ DGAC      1   8136.5 27410\n\nStep:  AIC=27385.32\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature + Latex + Macro\n\n           Df Deviance   AIC\n+ SMA       1   8127.9 27383\n+ DGAC      1   8129.7 27385\n<none>          8132.2 27385\n+ PCCP      1   8130.5 27386\n+ Gradient  1   8131.9 27387\n\nStep:  AIC=27383.04\nCrash ~ lnAADT + Friction + yn + Divided + LaneCount + Age + \n    IRI + Curvature + Latex + Macro + SMA\n\n           Df Deviance   AIC\n<none>          8120.2 27383\n+ DGAC      1   8119.0 27384\n+ PCCP      1   8119.0 27384\n+ Gradient  1   8119.9 27385\n\nsummary(StepWiseFit)\n\n\nCall:\nglm.nb(formula = Crash ~ lnAADT + Friction + yn + Divided + LaneCount + \n    Age + IRI + Curvature + Latex + Macro + SMA, data = FitData2, \n    init.theta = 0.9268485234, link = log)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7462  -0.9723  -0.5686   0.2126   7.4490  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -2.333449   0.236090  -9.884  < 2e-16 ***\nlnAADT        0.303521   0.014160  21.435  < 2e-16 ***\nFriction     -0.054863   0.002623 -20.915  < 2e-16 ***\nyn1           0.829530   0.036787  22.550  < 2e-16 ***\nDivided1      1.207650   0.050552  23.889  < 2e-16 ***\nLaneCount     0.542440   0.024544  22.100  < 2e-16 ***\nAge          -0.022080   0.002018 -10.943  < 2e-16 ***\nIRI           0.200922   0.020445   9.827  < 2e-16 ***\nCurvature   204.398987  29.403738   6.951 3.62e-12 ***\nLatex1       -0.350783   0.068954  -5.087 3.63e-07 ***\nMacro        -0.471428   0.087670  -5.377 7.56e-08 ***\nSMA1          0.080317   0.039742   2.021   0.0433 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.9268) family taken to be 1)\n\n    Null deviance: 14113.4  on 8815  degrees of freedom\nResidual deviance:  8120.2  on 8804  degrees of freedom\nAIC: 27385\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.9268 \n          Std. Err.:  0.0266 \n\n 2 x log-likelihood:  -27359.0430 \n\nsummary(StepWiseFit)$coefficients\n\n                Estimate   Std. Error    z value      Pr(>|z|)\n(Intercept)  -2.33344930  0.236090474  -9.883708  4.898601e-23\nlnAADT        0.30352129  0.014160144  21.434901 6.316823e-102\nFriction     -0.05486347  0.002623175 -20.914910  3.917635e-97\nyn1           0.82953006  0.036786588  22.549796 1.349053e-112\nDivided1      1.20765000  0.050551760  23.889376 3.949606e-126\nLaneCount     0.54244042  0.024544432  22.100345 3.136613e-108\nAge          -0.02207983  0.002017757 -10.942757  7.197696e-28\nIRI           0.20092202  0.020445238   9.827326  8.586842e-23\nCurvature   204.39898667 29.403737606   6.951463  3.615179e-12\nLatex1       -0.35078254  0.068954031  -5.087194  3.633999e-07\nMacro        -0.47142753  0.087669743  -5.377312  7.560621e-08\nSMA1          0.08031675  0.039741777   2.020965  4.328337e-02\n\n# Create a histogram of predicted counts\nhist(StepWiseFit$fitted.values, \n     main = \"Distribution of Predicted Crash Probabilities\",\n     xlab = \"Predicted Probabilities\", \n     ylab = \"Frequency\",\n          col = \"green\", \n     border = \"black\", \n     breaks = 20)"
  },
  {
    "objectID": "posts/Linear_Non-linear Regression/index.html",
    "href": "posts/Linear_Non-linear Regression/index.html",
    "title": "Linear/Non-linear Regression",
    "section": "",
    "text": "In my predictive modeling approach, I employed a Random Forest model to predict the occurrence of crashes. Random Forest is an ensemble learning method that combines the predictions of multiple decision trees to enhance overall accuracy and robustness. The data set used for modeling contained a variety of relevant features such as mix types, lane counts, roadway geometry, pavement condition, and environmental characteristics, which could influence crash outcome.\nI began by splitting the data set into training and testing sets to evaluate the model’s performance. The Random Forest algorithm was then applied to the training data, where a multitude of decision trees were constructed, each trained on a different subset of the data and considering a random subset of features for each split. This diversity and randomness helped mitigate overfitting and increased the model’s generalization ability. During the prediction phase, the ensemble of trees collectively contributed to a more accurate and stable prediction of crash occurrences.\n\n                   # Random Forest Regression\n\n#Loading dataset\nsetwd('C:/Users/behro/OneDrive/Desktop/SS-Infrastructure/project')\n\n#Install the packages\nlibrary(MASS)\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.2.3\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\nlibrary(caTools)\n\nWarning: package 'caTools' was built under R version 4.2.3\n\n#install.packages(\"randomForest\")\n#install.packages(\"pdp\")\n#install.packages(\"randomForestExplainer\")\n#install.packages(\"ggplot2\")\n#install.packages(\"Boruta\")\nlibrary(Boruta)\n\nWarning: package 'Boruta' was built under R version 4.2.3\n\nlibrary(randomForest)\nlibrary(randomForestExplainer)\n\nWarning: package 'randomForestExplainer' was built under R version 4.2.3\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:randomForest':\n\n    margin\n\n# View the structure of the data set (Read in data)\nFitData2<-read.csv('Book3.csv') \nnames(FitData2)#looking at the data\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\n#splitting data into training and testing\nsplit <- sample.split(FitData2, SplitRatio=0.7)\ntrain <- subset(FitData2, split==\"TRUE\")\ntest <- subset (FitData2, split==\"FALSE\")\n\n# Fitting the random forest model\nset.seed(100) #Setting seed\nclassRF= randomForest(x=train[-13], y=train$Crash, ntree=500)\nclassRF\n\n\nCall:\n randomForest(x = train[-13], y = train$Crash, ntree = 500) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 6\n\n          Mean of squared residuals: 0.8465309\n                    % Var explained: 95.66\n\n#Model prediction\nrf_model=predict(classRF, newdata= test[-13])\nsummary(rf_model)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0191  0.9753  2.0106  2.0130 38.2434 \n\n# Create a scatterplot of actual vs. predicted values\nplot(classRF$predicted, train$Crash,\n     main = \"Scatterplot of Actual vs. Predicted Values\",\n     xlab = \"Actual Values\", ylab = \"Predicted Values\",\n     col = \"darkblue\", pch = 16)\n\n# Add a diagonal line for reference\nabline(a = 0, b = 1, col = \"red\", lty = 2)"
  },
  {
    "objectID": "posts/Linear_Non-linear Regression/index.html#running-code",
    "href": "posts/Linear_Non-linear Regression/index.html#running-code",
    "title": "Post With Code",
    "section": "Running Code",
    "text": "Running Code\n\n                   # Random Forest Regression\n\n#Loading dataset\nsetwd('C:/Users/behro/OneDrive/Desktop/SS-Infrastructure/project')\n\n#Install the packages\nlibrary(MASS)\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.2.3\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\nlibrary(caTools)\n\nWarning: package 'caTools' was built under R version 4.2.3\n\n#install.packages(\"randomForest\")\n#install.packages(\"pdp\")\n#install.packages(\"randomForestExplainer\")\n#install.packages(\"ggplot2\")\n#install.packages(\"Boruta\")\nlibrary(Boruta)\n\nWarning: package 'Boruta' was built under R version 4.2.3\n\nlibrary(randomForest)\nlibrary(randomForestExplainer)\n\nWarning: package 'randomForestExplainer' was built under R version 4.2.3\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:randomForest':\n\n    margin\n\n# View the structure of the data set (Read in data)\nFitData2<-read.csv('Book3.csv') \nnames(FitData2)#looking at the data\n\n [1] \"AADT\"         \"Latitude\"     \"Longitude\"    \"yn\"           \"Divided\"     \n [6] \"LaneCount\"    \"DGAC\"         \"Latex\"        \"SMA\"          \"PCCP\"        \n[11] \"Age\"          \"Friction\"     \"Macro\"        \"IRI\"          \"Gradient\"    \n[16] \"Curvature\"    \"LatitudeGPS\"  \"LongitudeGps\" \"Crash\"        \"lnAADT\"      \n\n#splitting data into training and testing\nsplit <- sample.split(FitData2, SplitRatio=0.7)\ntrain <- subset(FitData2, split==\"TRUE\")\ntest <- subset (FitData2, split==\"FALSE\")\n\n# Fitting the random forest model\nset.seed(100) #Setting seed\nclassRF= randomForest(x=train[-13], y=train$Crash, ntree=500)\nclassRF\n\n\nCall:\n randomForest(x = train[-13], y = train$Crash, ntree = 500) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 6\n\n          Mean of squared residuals: 0.9273585\n                    % Var explained: 95.26\n\n#Model prediction\nrf_model=predict(classRF, newdata= test[-13])\nsummary(rf_model)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n 0.00000  0.01837  0.94287  1.98225  2.03440 41.59207 \n\n# Create a scatterplot of actual vs. predicted values\nplot(classRF$predicted, train$Crash,\n     main = \"Scatterplot of Actual vs. Predicted Values\",\n     xlab = \"Actual Values\", ylab = \"Predicted Values\",\n     col = \"darkblue\", pch = 16)\n\n# Add a diagonal line for reference\nabline(a = 0, b = 1, col = \"red\", lty = 2)"
  }
]